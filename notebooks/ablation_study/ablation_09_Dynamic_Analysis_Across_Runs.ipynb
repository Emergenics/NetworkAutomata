{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe596c76",
   "metadata": {},
   "source": [
    "# Cell 0: Notebook Header & Documentation\n",
    "# Description: Provides context and instructions for this notebook.\n",
    "\n",
    "## Notebook Title: Ablation Study - Dynamic Analysis Across Runs\n",
    "\n",
    "### Purpose and Context\n",
    "\n",
    "*   **Goal:** To perform a consistent **dynamic region analysis** across all simulation runs conducted in the Ablation Study (`ablation_01` through `ablation_07`). This notebook applies a uniform metric (time-averaged absolute state change) to identify dynamically active regions in each simulation history, regardless of whether the simulation converged to a static state.\n",
    "*   **Contribution:** Implements the defined dynamic region identification logic. Loads simulation histories from all run output folders. Calculates dynamic region sizes and their overlap with static baseline node sets (Degree, RWR). Compiles these dynamic metrics into a comparative table across all ruleset variants.\n",
    "*   **Inputs:**\n",
    "    *   Requires the baseline configuration file (`baseline_config.json`) saved by `ablation_00`.\n",
    "    *   Requires the history files (`*_history_analysis.csv`) saved by each simulation run (`ablation_01` through `ablation_07`) in their respective output folders.\n",
    "    *   Requires the static baseline node lists (Degree, RWR) potentially saved during earlier analysis (e.g., Cell 11.1 or 3.05 equivalent in run notebooks, or from `ablation_00` output if saved there).\n",
    "*   **Outputs:**\n",
    "    *   A dedicated analysis output folder (`biological_analysis_results/Dynamic_Analysis_Across_Runs`).\n",
    "    *   Saved dynamic region node lists for each run (e.g., `dynamic_region_nodes_run_label.txt`).\n",
    "    *   A summary CSV file containing the comparative dynamic metrics table.\n",
    "    *   A markdown summary of the dynamic analysis findings.\n",
    "\n",
    "### How to Run\n",
    "\n",
    "*   **Prerequisites:** Ensure `ablation_00_Setup_and_Definitions.ipynb` and ALL simulation notebooks (`ablation_01` through `ablation_07`, including the 4D Bio run) have been run successfully. This ensures all necessary history files and the baseline config are available. Ensure the Canonical Helper Functions for dynamic analysis are defined in Cell 1.1 of THIS notebook.\n",
    "*   **Configuration:** No user edits are required; Cell 1 loads the baseline config and defines the consistent dynamic region parameters. Cell 2 defines the mapping from analysis labels to run folders.\n",
    "*   **Execution:** Run all cells sequentially from top to bottom (Cell 0 through Cell 9).\n",
    "*   **Expected Runtime:** Moderate, depends on the size of simulation histories and number of runs. Primarily involves loading and processing data in memory.\n",
    "\n",
    "### Expected Results & Analysis (within this notebook)\n",
    "\n",
    "*   This notebook loads the histories (primarily Act/Inh CSVs) for all runs.\n",
    "*   It calculates the specified dynamic region metric (time-averaged absolute Act/Inh change) for each node in each run.\n",
    "*   It applies the percentile threshold to identify dynamic nodes consistently.\n",
    "*   It calculates dynamic region sizes and their overlap (Jaccard) with static baseline node lists (Degree, RWR).\n",
    "*   It compiles a table comparing these dynamic metrics across all runs.\n",
    "*   A final markdown summary interprets how different ruleset variants influence the system's propensity for sustained dynamic activity. This table will be used for the final paper draft synthesis in `ablation_11`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c86f7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 1: Load Configuration and Define Dynamic Analysis Parameters (2025-04-28 21:17:19) ---\n",
      "  ✅ Loaded baseline configuration from: simulation_results/Ablation_Setup_Files/baseline_config.json\n",
      "  Base Experiment Name loaded and set globally: string_ca_subgraph_AIFM1_CORRECTED\n",
      "\n",
      "--- Consistent Dynamic Region Analysis Parameters ---\n",
      "  Window: Last 20% of steps\n",
      "  Metric: Time-Avg Abs Change (|Act_t+1-Act_t|, |Inh_t+1-Inh_t|)\n",
      "  Threshold: Above 80th percentile of metric values across nodes\n",
      "\n",
      "Analysis outputs will be saved in: /home/irbsurfer/Projects/Novyte/Emergenics/production/emergenics/1_NetworkIStheComputation/ablation_study/biological_analysis_results/Dynamic_Analysis_Across_Runs\n",
      "   ✅ Saved dynamic analysis configuration to biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_analysis_config.json\n",
      "\n",
      "Cell 1: Configuration loaded and dynamic analysis parameters defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load Configuration and Define Dynamic Analysis Parameters\n",
    "# Description: Loads the baseline configuration to get directory paths and\n",
    "#              defines the parameters for the consistent dynamic region analysis.\n",
    "#              MODIFIED: Ensures BASE_EXPERIMENT_NAME is set as a global variable.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import traceback\n",
    "import warnings\n",
    "import numpy as np # Needed for np.nan checks later\n",
    "\n",
    "print(f\"\\n--- Cell 1: Load Configuration and Define Dynamic Analysis Parameters ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Load Baseline Configuration ---\n",
    "config_load_error = False\n",
    "baseline_config = {}\n",
    "setup_output_dir_load = os.path.join(\"simulation_results\", \"Ablation_Setup_Files\")\n",
    "\n",
    "try:\n",
    "    config_path_load = os.path.join(setup_output_dir_load, \"baseline_config.json\")\n",
    "    if not os.path.exists(config_path_load): raise FileNotFoundError(f\"Baseline config file not found: {config_path_load}. Run ablation_00.\")\n",
    "    with open(config_path_load, 'r') as f: baseline_config = json.load(f)\n",
    "    print(f\"  ✅ Loaded baseline configuration from: {config_path_load}\")\n",
    "\n",
    "    # Extract needed base parameters\n",
    "    OUTPUT_DIR_SIMULATIONS = baseline_config.get('OUTPUT_DIR', \"simulation_results\") # Base dir for sim outputs\n",
    "    ANALYSIS_DIR_BASE = baseline_config.get('ANALYSIS_DIR', \"biological_analysis_results\") # Base dir for THIS notebook's output\n",
    "\n",
    "    # --- Extract BASE_EXPERIMENT_NAME and set as GLOBAL ---\n",
    "    BASE_EXPERIMENT_NAME = baseline_config.get('EXPERIMENT_NAME', 'string_ca_subgraph_AIFM1_CORRECTED') # Base name from ablation_00 config\n",
    "    globals()['BASE_EXPERIMENT_NAME'] = BASE_EXPERIMENT_NAME # ** Set as global variable **\n",
    "    print(f\"  Base Experiment Name loaded and set globally: {BASE_EXPERIMENT_NAME}\")\n",
    "    # --- END MODIFIED ---\n",
    "\n",
    "    # --- Extract other relevant globals from baseline config ---\n",
    "    MASTER_SEED = baseline_config.get('MASTER_SEED', 42) # Keep seed for consistency if needed\n",
    "    TARGET_NODE_ID = baseline_config.get('TARGET_NODE_ID') # Target ID for baselines\n",
    "    TARGET_NODE_NAME = baseline_config.get('TARGET_NODE_NAME', 'TargetProtein') # Target Name\n",
    "\n",
    "    # Set these as globals for helper functions\n",
    "    globals()['MASTER_SEED'] = MASTER_SEED\n",
    "    globals()['TARGET_NODE_ID'] = TARGET_NODE_ID\n",
    "    globals()['TARGET_NODE_NAME'] = TARGET_NODE_NAME\n",
    "    globals()['OUTPUT_DIR_SIMULATIONS'] = OUTPUT_DIR_SIMULATIONS\n",
    "    globals()['ANALYSIS_DIR_BASE'] = ANALYSIS_DIR_BASE\n",
    "    # --- END Extract and Set GLOBALS ---\n",
    "\n",
    "\n",
    "except FileNotFoundError as e: print(f\"❌ ERROR: {e}\"); config_load_error = True\n",
    "except Exception as e: print(f\"❌ Error loading config data: {e}\"); traceback.print_exc(limit=1); config_load_error = True\n",
    "\n",
    "\n",
    "# --- Define Consistent Dynamic Region Analysis Parameters ---\n",
    "# Based on user's clarified definition (time-averaged absolute change over window)\n",
    "\n",
    "# 1. Window: Use the last 20% of steps\n",
    "DYNAMIC_WINDOW_FRACTION = 0.20\n",
    "# 2. Metric: Time-averaged absolute state CHANGE over the window (Act/Inh only)\n",
    "DYNAMIC_METRIC_NAME = \"Time-Avg Abs Change (|Act_t+1-Act_t|, |Inh_t+1-Inh_t|)\" # Descriptive name\n",
    "DYNAMIC_METRIC_KEY = 'time_avg_abs_change' # Internal key\n",
    "# 3. Threshold: Above the 80th-percentile of this metric across all nodes in the final step\n",
    "DYNAMIC_THRESHOLD_TYPE = 'percentile'\n",
    "DYNAMIC_THRESHOLD_VALUE = 80 # 80th percentile\n",
    "\n",
    "# --- Set these parameters as GLOBALS ---\n",
    "globals()['DYNAMIC_WINDOW_FRACTION'] = DYNAMIC_WINDOW_FRACTION\n",
    "globals()['DYNAMIC_METRIC_NAME'] = DYNAMIC_METRIC_NAME\n",
    "globals()['DYNAMIC_METRIC_KEY'] = DYNAMIC_METRIC_KEY\n",
    "globals()['DYNAMIC_THRESHOLD_TYPE'] = DYNAMIC_THRESHOLD_TYPE\n",
    "globals()['DYNAMIC_THRESHOLD_VALUE'] = DYNAMIC_THRESHOLD_VALUE\n",
    "# --- END Set GLOBALS ---\n",
    "\n",
    "print(\"\\n--- Consistent Dynamic Region Analysis Parameters ---\")\n",
    "print(f\"  Window: Last {DYNAMIC_WINDOW_FRACTION*100:.0f}% of steps\")\n",
    "print(f\"  Metric: {DYNAMIC_METRIC_NAME}\")\n",
    "print(f\"  Threshold: Above {DYNAMIC_THRESHOLD_VALUE}th percentile of metric values across nodes\")\n",
    "\n",
    "# --- Define Output Directory for this Analysis Notebook ---\n",
    "OUTPUT_DIR_DYNAMIC_ANALYSIS = os.path.join(ANALYSIS_DIR_BASE, \"Dynamic_Analysis_Across_Runs\")\n",
    "os.makedirs(OUTPUT_DIR_DYNAMIC_ANALYSIS, exist_ok=True)\n",
    "globals()['OUTPUT_DIR_DYNAMIC_ANALYSIS'] = OUTPUT_DIR_DYNAMIC_ANALYSIS # Set as global\n",
    "print(f\"\\nAnalysis outputs will be saved in: {os.path.join(os.getcwd(), OUTPUT_DIR_DYNAMIC_ANALYSIS)}\") # Show full path\n",
    "\n",
    "\n",
    "# --- Save Dynamic Analysis Config ---\n",
    "analysis_config_save_path = os.path.join(OUTPUT_DIR_DYNAMIC_ANALYSIS, \"dynamic_analysis_config.json\")\n",
    "try:\n",
    "    analysis_config_dict = {\n",
    "         'DYNAMIC_WINDOW_FRACTION': DYNAMIC_WINDOW_FRACTION,\n",
    "         'DYNAMIC_METRIC_NAME': DYNAMIC_METRIC_NAME,\n",
    "         'DYNAMIC_METRIC_KEY': DYNAMIC_METRIC_KEY,\n",
    "         'DYNAMIC_THRESHOLD_TYPE': DYNAMIC_THRESHOLD_TYPE,\n",
    "         'DYNAMIC_THRESHOLD_VALUE': DYNAMIC_THRESHOLD_VALUE,\n",
    "         'OUTPUT_DIR_DYNAMIC_ANALYSIS': OUTPUT_DIR_DYNAMIC_ANALYSIS,\n",
    "         'TARGET_NODE_ID': TARGET_NODE_ID,\n",
    "         'TARGET_NODE_NAME': TARGET_NODE_NAME,\n",
    "         'MASTER_SEED': MASTER_SEED # Include seed for record-keeping\n",
    "    }\n",
    "    with open(analysis_config_save_path, 'w') as f:\n",
    "        json.dump(analysis_config_dict, f, indent=4, default=str) # Use default=str for numpy types\n",
    "    print(f\"   ✅ Saved dynamic analysis configuration to {analysis_config_save_path}\")\n",
    "except Exception as e: print(f\"   ⚠️ Warning: Could not save dynamic analysis configuration: {e}\")\n",
    "\n",
    "print(\"\\nCell 1: Configuration loaded and dynamic analysis parameters defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58ed07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 1.1: Defining Canonical Helper Functions for Dynamic Analysis (2025-04-28 21:17:19) ---\n",
      "\n",
      "Cell 1.1: Canonical Helper Functions for Dynamic Analysis defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1.1: Canonical Helper Functions for Dynamic Analysis\n",
    "# Description: Defines all necessary helper functions for loading history data,\n",
    "#              calculating the dynamic region metric, identifying dynamic nodes,\n",
    "#              loading static baseline node lists, and calculating overlaps.\n",
    "#              These functions are self-contained within this notebook.\n",
    "#              MODIFIED: Includes function for calculating time-averaged absolute CHANGE.\n",
    "#              MODIFIED: Added warning suppression in load_history_dfs for non-numeric checks.\n",
    "#              MODIFIED: Corrected logic in load_static_baseline_nodes to handle file not found more explicitly\n",
    "#                        and avoid printing the \"Loaded X nodes for baseline check\" message if the file isn't used.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import pickle # Needed for loading pkl files\n",
    "import traceback\n",
    "\n",
    "print(f\"\\n--- Cell 1.1: Defining Canonical Helper Functions for Dynamic Analysis ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Helper Function: Load History DataFrames from Run Folder ---\n",
    "def load_history_dfs(run_folder_name, base_sim_output_dir):\n",
    "    \"\"\"\n",
    "    Loads activation and inhibition history DataFrames from a simulation run folder.\n",
    "    Returns (act_df, inh_df) or (None, None) on failure.\n",
    "    Looks for filenames like 'activation_history_analysis.csv' or 'activation_history.csv'.\n",
    "    Suppresses UserWarnings during non-numeric dtype checks.\n",
    "    \"\"\"\n",
    "    act_df = None; inh_df = None\n",
    "    run_output_dir = os.path.join(base_sim_output_dir, run_folder_name)\n",
    "    # Prioritize 'analysis' suffixed files, fall back to standard names\n",
    "    act_paths = [os.path.join(run_output_dir, \"activation_history_analysis.csv\"), os.path.join(run_output_dir, \"activation_history.csv\")]\n",
    "    inh_paths = [os.path.join(run_output_dir, \"inhibition_history_analysis.csv\"), os.path.join(run_output_dir, \"inhibition_history.csv\")]\n",
    "\n",
    "    try:\n",
    "        found_act_path = next((p for p in act_paths if os.path.exists(p)), None)\n",
    "        if found_act_path:\n",
    "            # Use float dtype hint during read for performance/robustness if possible\n",
    "            act_df = pd.read_csv(found_act_path, index_col=0, dtype=float, low_memory=False)\n",
    "            # print(f\"    Loaded Act history from: {os.path.basename(found_act_path)}\") # Too verbose\n",
    "        else: warnings.warn(f\"    Act history not found for {run_folder_name}.\")\n",
    "\n",
    "        found_inh_path = next((p for p in inh_paths if os.path.exists(p)), None)\n",
    "        if found_inh_path:\n",
    "             inh_df = pd.read_csv(found_inh_path, index_col=0, dtype=float, low_memory=False)\n",
    "             # print(f\"    Loaded Inh history from: {os.path.basename(found_inh_path)}\") # Too verbose\n",
    "        else: warnings.warn(f\"    Inh history not found for {run_folder_name}.\")\n",
    "\n",
    "        if act_df is None or inh_df is None: return None, None # Return None if either failed to load\n",
    "        if act_df.empty or inh_df.empty: warnings.warn(f\"    Loaded history DF(s) empty for {run_folder_name}.\"); return None, None\n",
    "        if act_df.shape != inh_df.shape: warnings.warn(f\"    History DF shape mismatch for {run_folder_name}: Act={act_df.shape}, Inh={inh_df.shape}. Using common steps/nodes.\");\n",
    "        # Harmonize dataframes based on common indices and columns\n",
    "        common_indices = act_df.index.intersection(inh_df.index)\n",
    "        common_columns = act_df.columns.intersection(inh_df.columns)\n",
    "        act_df = act_df.loc[common_indices, common_columns]\n",
    "        inh_df = inh_df.loc[common_indices, common_columns]\n",
    "        if act_df.empty or inh_df.empty: warnings.warn(f\"    History DF(s) empty after harmonization for {run_folder_name}.\"); return None, None\n",
    "\n",
    "        # --- MODIFIED: Add warning suppression around the numeric dtype check ---\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") # Suppress UserWarnings (like 'Non-numeric data detected')\n",
    "            # Check for potential non-numeric data after loading - this check can raise UserWarnings\n",
    "            # if there are mixed types or pandas isn't sure. The dtype=float hint helps.\n",
    "            if not pd.api.types.is_numeric_dtype(act_df.values) or not pd.api.types.is_numeric_dtype(inh_df.values):\n",
    "                # If despite dtype=float, it's still not purely numeric, try coercion.\n",
    "                 # The original warning message will be suppressed by the catch_warnings block.\n",
    "                 print(f\"    Attempting coercion to numeric for history DFs for {run_folder_name}.\")\n",
    "                 act_df = act_df.apply(pd.to_numeric, errors='coerce')\n",
    "                 inh_df = inh_df.apply(pd.to_numeric, errors='coerce')\n",
    "                 if act_df.isnull().all().all() or inh_df.isnull().all().all():\n",
    "                      warnings.warn(f\"    Coercion failed, DFs are all NaN for {run_folder_name}. Skipping.\")\n",
    "                      return None, None # Return None if coercion fails completely\n",
    "        # --- END MODIFIED ---\n",
    "\n",
    "\n",
    "        return act_df, inh_df # Return successfully loaded/harmonized DFs\n",
    "\n",
    "    except FileNotFoundError:\n",
    "         # This case is covered by the checks inside the try block\n",
    "         return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error loading history DataFrames for {run_folder_name}: {e}\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        return None, None # Return None on any loading/processing error\n",
    "\n",
    "# --- Helper Function: Calculate Time-Averaged Absolute State Change Metric ---\n",
    "# MODIFIED: Implements the user's specified metric calculation.\n",
    "def calculate_time_avg_abs_change_metric(act_history_df, inh_history_df):\n",
    "    \"\"\"\n",
    "    Calculates the time-averaged absolute change in Act/Inh for each node\n",
    "    over the final window, based on the user's defined metric.\n",
    "    Returns a pandas Series {node_id: metric_value} or None.\n",
    "    \"\"\"\n",
    "    # Access parameters from GLOBALS\n",
    "    window_fraction = globals().get('DYNAMIC_WINDOW_FRACTION', 0.20)\n",
    "    metric_key = globals().get('DYNAMIC_METRIC_KEY', 'time_avg_abs_change') # For internal verification\n",
    "\n",
    "    if act_history_df is None or inh_history_df is None or act_history_df.empty or inh_history_df.empty:\n",
    "        warnings.warn(f\"    Cannot calculate '{metric_key}': Input DataFrames are missing or empty.\")\n",
    "        return None\n",
    "\n",
    "    if not act_history_df.index.equals(inh_history_df.index) or not act_history_df.columns.equals(inh_history_df.columns):\n",
    "        warnings.warn(f\"    Act/Inh DataFrames indices/columns do not match, using intersection.\")\n",
    "        common_indices = act_history_df.index.intersection(inh_history_df.index)\n",
    "        common_columns = act_history_df.columns.intersection(inh_history_df.columns)\n",
    "        act_history_df = act_history_df.loc[common_indices, common_columns]\n",
    "        inh_history_df = inh_history_df.loc[common_indices, common_columns]\n",
    "        if act_history_df.empty:\n",
    "             warnings.warn(f\"    DFs became empty after harmonization, cannot calculate '{metric_key}'.\")\n",
    "             return None\n",
    "\n",
    "\n",
    "    num_steps_hist = len(act_history_df)\n",
    "    if num_steps_hist < 2:\n",
    "        warnings.warn(f\"    History has < 2 steps ({num_steps_hist}), cannot calculate state change.\")\n",
    "        return None # Cannot calculate change if only 1 step or less\n",
    "\n",
    "    # Calculate step-wise absolute change for Act and Inh\n",
    "    # Use diff() which calculates change between adjacent steps\n",
    "    abs_change_act = act_history_df.diff().abs()\n",
    "    abs_change_inh = inh_history_df.diff().abs()\n",
    "\n",
    "    # Combine absolute changes (element-wise maximum)\n",
    "    abs_change_max = pd.DataFrame(np.maximum(abs_change_act.values, abs_change_inh.values), index=act_history_df.index, columns=act_history_df.columns)\n",
    "\n",
    "\n",
    "    # Determine the window\n",
    "    # Start window from the beginning of the history if it's shorter than window size\n",
    "    window_length = max(1, int(window_fraction * num_steps_hist)) # Ensure window is at least 1 step\n",
    "    window_start_index = num_steps_hist - window_length\n",
    "\n",
    "    # Select the window from the changes DataFrame (excluding the first step's NaN change)\n",
    "    # The first row of abs_change_max is NaN, so window starts from index 1\n",
    "    window_changes = abs_change_max.iloc[max(1, window_start_index) :] # Ensure window starts at index 1 or later\n",
    "\n",
    "    if window_changes.empty:\n",
    "         warnings.warn(f\"    Calculated window is empty ({window_length} steps from {num_steps_hist}). Cannot calculate time-averaged change.\")\n",
    "         # Return Series of NaN keyed by node ID, matching original DataFrame columns\n",
    "         return pd.Series(np.nan, index=act_history_df.columns)\n",
    "\n",
    "    # Calculate the time-averaged change over the window for each node (mean across time steps)\n",
    "    # Use .mean(axis=0) on the DataFrame for mean across rows (time) for each column (node)\n",
    "    # Handle potential NaNs within the window data if they exist\n",
    "    time_averaged_metric_per_node = window_changes.mean(axis=0) # Mean across rows (time)\n",
    "\n",
    "    # Return as a pandas Series indexed by node ID\n",
    "    return time_averaged_metric_per_node\n",
    "\n",
    "\n",
    "# --- Helper Function: Identify Dynamic Nodes based on Metric ---\n",
    "# MODIFIED: Implements the user's specified thresholding logic.\n",
    "def identify_dynamic_nodes(node_metric_series):\n",
    "    \"\"\"\n",
    "    Identifies nodes whose metric value is above the percentile threshold.\n",
    "    Returns a list of node IDs.\n",
    "    \"\"\"\n",
    "    # Access parameters from GLOBALS\n",
    "    threshold_type = globals().get('DYNAMIC_THRESHOLD_TYPE', 'percentile')\n",
    "    threshold_value = globals().get('DYNAMIC_THRESHOLD_VALUE', 80)\n",
    "    metric_key = globals().get('DYNAMIC_METRIC_KEY', 'metric_value') # For warning messages\n",
    "\n",
    "    if node_metric_series is None or node_metric_series.empty:\n",
    "        warnings.warn(f\"    Cannot identify dynamic nodes: Input metric series is missing or empty.\")\n",
    "        return []\n",
    "\n",
    "    # Exclude NaN values from the metric distribution for threshold calculation\n",
    "    valid_metric_values = node_metric_series.dropna().values\n",
    "\n",
    "    if len(valid_metric_values) == 0:\n",
    "        warnings.warn(f\"    All metric values are NaN, cannot determine threshold or dynamic nodes.\")\n",
    "        return []\n",
    "    if len(valid_metric_values) < 2 and threshold_type == 'percentile':\n",
    "         warnings.warn(f\"    Fewer than 2 valid metric values ({len(valid_metric_values)}), percentile threshold unreliable/impossible. Using median as threshold fallback.\")\n",
    "         # Fallback to median if percentile is requested but insufficient data\n",
    "         threshold_type = 'absolute'\n",
    "         threshold_value = np.median(valid_metric_values) if valid_metric_values.size > 0 else 0.0\n",
    "\n",
    "\n",
    "    actual_threshold = np.nan # Initialize\n",
    "\n",
    "    if threshold_type == 'percentile':\n",
    "        percentile = threshold_value # Use the value directly (e.g., 80)\n",
    "        if not (0 <= percentile <= 100):\n",
    "             warnings.warn(f\"    Percentile threshold value out of bounds (0-100): {percentile}. Using 80th percentile.\")\n",
    "             percentile = 80\n",
    "        try:\n",
    "            actual_threshold = np.percentile(valid_metric_values, percentile)\n",
    "            # print(f\"    Using {percentile}th percentile threshold: {actual_threshold:.6f}\") # Print in calling cell\n",
    "        except Exception as e:\n",
    "             warnings.warn(f\"    Error calculating percentile threshold: {e}. Cannot identify dynamic nodes.\")\n",
    "             return [] # Return empty list on error\n",
    "\n",
    "    elif threshold_type == 'absolute':\n",
    "        actual_threshold = threshold_value # Use the value directly\n",
    "        # print(f\"    Using absolute threshold: {actual_threshold:.6f}\") # Print in calling cell\n",
    "    else:\n",
    "        warnings.warn(f\"    Unknown threshold type: '{threshold_type}'. Cannot identify dynamic nodes.\")\n",
    "        return [] # Return empty list on unknown type\n",
    "\n",
    "    if pd.isna(actual_threshold): # Should be set by now, but check for safety\n",
    "         warnings.warn(\"    Actual threshold value is NaN. Cannot identify dynamic nodes.\")\n",
    "         return []\n",
    "\n",
    "    # Identify nodes whose metric value is >= the calculated/determined threshold\n",
    "    # Use .loc to apply threshold to the Series and get the index (node IDs)\n",
    "    # Handle potential NaNs in the original series by filling temporarily for comparison >= threshold\n",
    "    dynamic_nodes_series = node_metric_series[np.nan_to_num(node_metric_series, nan=-np.inf) >= actual_threshold]\n",
    "\n",
    "    # Return the list of node IDs\n",
    "    return dynamic_nodes_series.index.tolist()\n",
    "\n",
    "\n",
    "# --- Helper Function: Load Static Baseline Node Lists ---\n",
    "def load_static_baseline_nodes(base_sim_output_dir):\n",
    "    \"\"\"\n",
    "    Loads Degree and RWR baseline node lists from the ablation_00 setup files.\n",
    "    Returns a dictionary {'Degree': list, 'RWR': list}.\n",
    "    MODIFIED: Corrected logic to handle file not found more explicitly\n",
    "              and avoid printing the \"Loaded X nodes for baseline check\" message if the file isn't used.\n",
    "    \"\"\"\n",
    "    baseline_nodes = {'Degree': [], 'RWR': []}\n",
    "    setup_dir = os.path.join(base_sim_output_dir, \"Ablation_Setup_Files\")\n",
    "\n",
    "    # Load Node List (needed to verify node IDs in baseline files)\n",
    "    # Check if node_list_analysis is available from Cell 3 setup if graph was loaded there\n",
    "    node_list_available = globals().get('node_list_analysis')\n",
    "    if node_list_available is None or not isinstance(node_list_available, list):\n",
    "         # Fallback to loading from file\n",
    "         node_list_path = os.path.join(setup_dir, \"node_list.pkl\")\n",
    "         node_list_available = None\n",
    "         if os.path.exists(node_list_path):\n",
    "              try:\n",
    "                  with open(node_list_path, 'rb') as f: node_list_available = pickle.load(f)\n",
    "                  if not isinstance(node_list_available, list): node_list_available = None; raise TypeError(\"Loaded node_list not list.\")\n",
    "                  # Print here only if successfully loaded from file\n",
    "                  print(f\"    Loaded {len(node_list_available) if node_list_available else 0} node IDs for baseline check.\")\n",
    "              except Exception as e: warnings.warn(f\"    Error loading node_list for baseline check: {e}\")\n",
    "         else: warnings.warn(f\"    Node list PKL not found at {node_list_path}. Cannot verify baseline nodes.\")\n",
    "\n",
    "\n",
    "    # Load baselines saved by ablation_00 or other runs\n",
    "    # Assuming the baseline nodes text file exists within the base_sim_output_dir\n",
    "    # This file is expected to be generated by ablation_00.\n",
    "    baseline_txt_path = os.path.join(base_sim_output_dir, \"baseline_nodes.txt\") # Assuming this name/location\n",
    "\n",
    "    if os.path.exists(baseline_txt_path):\n",
    "        try:\n",
    "            print(f\"    Loading static baseline node lists from: {baseline_txt_path}\")\n",
    "            current_section = None\n",
    "            with open(baseline_txt_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line.startswith(\"--- Baseline: Top Nodes by Degree ---\"):\n",
    "                        current_section = 'Degree'\n",
    "                    elif line.startswith(\"--- Baseline: Top Nodes by RWR from Target ---\"):\n",
    "                        current_section = 'RWR'\n",
    "                    # Add other sections if needed\n",
    "                    elif line.startswith(\"---\") or not line:\n",
    "                        continue # Skip section headers and empty lines\n",
    "                    elif current_section in baseline_nodes:\n",
    "                        # Add node ID to the current section's list\n",
    "                        node_id = line.strip()\n",
    "                        # Optional: Validate node_id is in node_list if loaded\n",
    "                        # Only add if node_list_available is None (no list to check against) OR if it's in the list\n",
    "                        if node_list_available is None or node_id in node_list_available:\n",
    "                             baseline_nodes[current_section].append(node_id)\n",
    "                        # else: warnings.warn(f\"    Skipping node ID '{node_id}' in baseline file, not in node_list.\")\n",
    "\n",
    "            print(f\"    Loaded baselines: Degree ({len(baseline_nodes['Degree'])}), RWR ({len(baseline_nodes['RWR'])}).\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Error loading static baseline node lists from file: {e}\")\n",
    "            traceback.print_exc(limit=1)\n",
    "            baseline_nodes = {'Degree': [], 'RWR': []} # Ensure empty lists on error\n",
    "    else:\n",
    "        # This warning is now outside the try/except for loading,\n",
    "        # specifically stating the file was not found.\n",
    "        warnings.warn(f\"    Static baseline node list file not found at {baseline_txt_path}. Cannot load static baselines.\")\n",
    "        # baseline_nodes remains {'Degree': [], 'RWR': []}\n",
    "\n",
    "    return baseline_nodes\n",
    "\n",
    "\n",
    "# --- Helper Function: Calculate Jaccard Index ---\n",
    "def calculate_jaccard_index(set1, set2):\n",
    "    \"\"\"Calculates Jaccard Index (Intersection / Union) for two sets.\"\"\"\n",
    "    if not isinstance(set1, (set, list)) or not isinstance(set2, (set, list)):\n",
    "        warnings.warn(\"    Jaccard input not sets/lists, attempting conversion.\")\n",
    "        try: set1 = set(set1); set2 = set(set2)\n",
    "        except Exception: warnings.warn(\"    Jaccard conversion failed.\"); return 0.0 # Return 0 if conversion fails\n",
    "    else: # If inputs were lists, convert to sets\n",
    "        set1 = set(set1); set2 = set(set2)\n",
    "\n",
    "\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "\n",
    "    if not union: # Handle empty sets\n",
    "        return 0.0\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "print(\"\\nCell 1.1: Canonical Helper Functions for Dynamic Analysis defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b5b08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 1.2: Define Helper Functions for Loading Analysis Data (2025-04-28 21:17:19) ---\n",
      "\n",
      "✅ Cell 1.2: Helper functions for loading analysis data defined. (2025-04-28 21:17:19)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1.2: Define Helper Functions for Loading Analysis Data\n",
    "# Description: Defines helper functions to load summary data and comparison tables\n",
    "#              from the output files of previous analysis notebooks.\n",
    "#              These functions are self-contained.\n",
    "#              MODIFIED: Includes helper for loading dynamic/dynamic_bio comparison tables.\n",
    "#              MODIFIED: Suppressed FileNotFoundError warnings in loading functions.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pickle # Needed for loading pkl files (e.g., backfilled averages)\n",
    "import pandas as pd # Needed for DataFrame loading\n",
    "import numpy as np # Needed for np.nan\n",
    "import traceback # Added import for traceback\n",
    "\n",
    "print(f\"\\n--- Cell 1.2: Define Helper Functions for Loading Analysis Data ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Helper Function: Load Simulation Run Summary (experiment_summary.json) ---\n",
    "# COPIED from ablation_09 Cell 1.1\n",
    "# MODIFIED: Corrected NameError when accessing mapped_symbols_dict.\n",
    "# MODIFIED: Corrected syntax for accessing dictionary items during backfilling.\n",
    "# MODIFIED: Accesses base_sim_output_dir from GLOBALS.\n",
    "def load_sim_summary(experiment_folder_name):\n",
    "    \"\"\"\n",
    "    Loads the experiment_summary.json file for a given run folder.\n",
    "    Optionally attempts to backfill average final dict values from pkl if missing.\n",
    "    Accesses base_sim_output_dir from GLOBALS.\n",
    "    Returns the summary dict or an empty dict on failure.\n",
    "    \"\"\"\n",
    "    # Access base_sim_output_dir from GLOBALS\n",
    "    base_sim_output_dir = globals().get('OUTPUT_DIR_SIMULATIONS')\n",
    "    if not base_sim_output_dir:\n",
    "         warnings.warn(\"load_sim_summary: OUTPUT_DIR_SIMULATIONS global not set.\")\n",
    "         return {} # Cannot proceed without the base directory\n",
    "\n",
    "    summary_path = os.path.join(base_sim_output_dir, experiment_folder_name, \"experiment_summary.json\")\n",
    "    summary_data = {}\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(summary_path):\n",
    "            with open(summary_path, 'r') as f:\n",
    "                summary_data = json.load(f)\n",
    "            # print(f\"  ✅ Loaded summary for {experiment_folder_name}\") # Too verbose\n",
    "\n",
    "            # --- Backfill average final dict value if missing from summary ---\n",
    "            avg_keys_to_check = ['final_average_pheromones', 'final_average_potentiation', 'final_average_dict_output']\n",
    "            avg_value_found = False\n",
    "            for key in avg_keys_to_check:\n",
    "                 if key in summary_data and pd.notna(summary_data.get(key)):\n",
    "                      avg_value_found = True\n",
    "                      break\n",
    "\n",
    "            if not avg_value_found:\n",
    "                 final_dict_path_phero = os.path.join(base_sim_output_dir, experiment_folder_name, \"final_pheromones.pkl\")\n",
    "                 final_dict_path_pot = os.path.join(base_sim_output_dir, experiment_folder_name, \"final_potentiation.pkl\")\n",
    "                 avg_final_dict_val = np.nan\n",
    "\n",
    "                 try:\n",
    "                      if os.path.exists(final_dict_path_phero):\n",
    "                           with open(final_dict_path_phero, 'rb') as f_pkl: final_dict = pickle.load(f_pkl)\n",
    "                           if isinstance(final_dict, dict) and final_dict:\n",
    "                                numeric_vals = [v for v in final_dict.values() if isinstance(v, (int, float)) and not np.isnan(v)]\n",
    "                                avg_final_dict_val = np.mean(numeric_vals) if numeric_vals else 0.0\n",
    "                                summary_data['final_average_pheromones_from_pkl'] = avg_final_dict_val\n",
    "                      elif os.path.exists(final_dict_path_pot):\n",
    "                            with open(final_dict_path_pot, 'rb') as f_pkl: final_dict = pickle.load(f_pkl)\n",
    "                            if isinstance(final_dict, dict) and final_dict:\n",
    "                                numeric_vals = [v for v in final_dict.values() if isinstance(v, (int, float)) and not np.isnan(v)]\n",
    "                                avg_final_dict_val = np.mean(numeric_vals) if numeric_vals else 0.0\n",
    "                                summary_data['final_average_potentiation_from_pkl'] = avg_final_dict_val\n",
    "                 except Exception as e_pkl:\n",
    "                      warnings.warn(f\"    Warning: Could not backfill average from pkl for {experiment_folder_name}: {e_pkl}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            warnings.warn(f\"Summary file not found for run: {experiment_folder_name}. Skipping.\")\n",
    "            return {}\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ Error decoding JSON summary for {experiment_folder_name}. File might be corrupt. Skipping.\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error loading summary for {experiment_folder_name}: {e}. Skipping.\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        return {}\n",
    "\n",
    "    return summary_data\n",
    "\n",
    "\n",
    "# --- Helper Function: Load Dynamic Analysis Comparison Table (from ablation_09) ---\n",
    "# NEW helper\n",
    "# MODIFIED: Suppressed FileNotFoundError warning.\n",
    "def load_dynamic_analysis_table():\n",
    "    \"\"\"\n",
    "    Loads the main comparison table from ablation_09's output.\n",
    "    Accesses output directory from GLOBALS (OUTPUT_DIR_DYNAMIC_ANALYSIS).\n",
    "    Returns the DataFrame or an empty DataFrame on failure.\n",
    "    \"\"\"\n",
    "    # Access output directory from GLOBALS\n",
    "    analysis_dir = globals().get('OUTPUT_DIR_DYNAMIC_ANALYSIS')\n",
    "    if not analysis_dir:\n",
    "         warnings.warn(\"load_dynamic_analysis_table: OUTPUT_DIR_DYNAMIC_ANALYSIS global not set.\")\n",
    "         return pd.DataFrame() # Cannot proceed without the directory\n",
    "\n",
    "    table_path = os.path.join(analysis_dir, \"dynamic_analysis_comparison_table.csv\") # Assumed filename from ablation_09\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(table_path):\n",
    "            # Use index_col=0 if the first column is the run label\n",
    "            df = pd.read_csv(table_path, index_col=0)\n",
    "            print(f\"  ✅ Loaded dynamic analysis comparison table from: {table_path}\")\n",
    "        else:\n",
    "            # MODIFIED: Print error message but do NOT issue a warning for FileNotFoundError\n",
    "            print(f\"❌ Error: Dynamic analysis comparison table not found at: {table_path}. Skipping.\")\n",
    "            # END MODIFIED\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading dynamic analysis comparison table: {e}\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        df = pd.DataFrame() # Ensure empty DF on error\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Helper Function: Load Dynamic Biological Enrichment Table (from ablation_10) ---\n",
    "# NEW helper\n",
    "# MODIFIED: Suppressed FileNotFoundError warning.\n",
    "def load_dynamic_bio_enrichment_table():\n",
    "    \"\"\"\n",
    "    Loads the comparative enrichment table from ablation_10's output.\n",
    "    Accesses output directory from GLOBALS (OUTPUT_DIR_DYNAMIC_BIO_ANALYSIS).\n",
    "    Returns the DataFrame or an empty DataFrame on failure.\n",
    "    \"\"\"\n",
    "    # Access output directory from GLOBALS\n",
    "    analysis_dir = globals().get('OUTPUT_DIR_DYNAMIC_BIO_ANALYSIS')\n",
    "    if not analysis_dir:\n",
    "         warnings.warn(\"load_dynamic_bio_enrichment_table: OUTPUT_DIR_DYNAMIC_BIO_ANALYSIS global not set.\")\n",
    "         return pd.DataFrame() # Cannot proceed without the directory\n",
    "\n",
    "    table_path = os.path.join(analysis_dir, \"dynamic_biological_enrichment_comparison_table.csv\") # Assumed filename from ablation_10\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(table_path):\n",
    "            # Use index_col=0 if the first column is the run label\n",
    "            df = pd.read_csv(table_path, index_col=0)\n",
    "            print(f\"  ✅ Loaded dynamic biological enrichment table from: {table_path}\")\n",
    "        else:\n",
    "            # MODIFIED: Print error message but do NOT issue a warning for FileNotFoundError\n",
    "            print(f\"❌ Error: Dynamic biological enrichment table not found at: {table_path}. Skipping.\")\n",
    "            # END MODIFIED\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading dynamic biological enrichment table: {e}\")\n",
    "        traceback.print_exc(limit=1)\n",
    "        df = pd.DataFrame() # Ensure empty DF on error\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "print(f\"\\n✅ Cell 1.2: Helper functions for loading analysis data defined. ({time.strftime('%Y-%m-%d %H:%M:%S')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e785bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 2: Define Run Folders (2025-04-28 21:17:20) ---\n",
      "Defined mapping of run labels to expected folder names for dynamic analysis:\n",
      "  'H+P (2D Ref)': 'string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonicPheromone_REF'\n",
      "  'P-Only (2D)': 'string_ca_subgraph_AIFM1_CORRECTED_LinearPheromoneOnly'\n",
      "  'H-Only (2D)': 'string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonicOnly'\n",
      "  'H+3D-PH (Coupled)': 'string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim3D'\n",
      "  'H+5D-PH (Coupled)': 'string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim5D'\n",
      "  'H+5D-PH (Decoupled)': 'string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim5D_DecoupledDiff'\n",
      "  'H+4D-Bio (AIFM1)': 'string_ca_subgraph_AIFM1_CORRECTED_Harmonic4DBio'\n",
      "\n",
      "Cell 2: Run folders defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Define Run Folders\n",
    "# Description: Defines the mapping from human-readable labels to the actual\n",
    "#              experiment folder names for ALL relevant runs (01-07).\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(f\"\\n--- Cell 2: Define Run Folders ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# Ensure BASE_EXPERIMENT_NAME is defined globally\n",
    "if 'BASE_EXPERIMENT_NAME' not in globals() or not BASE_EXPERIMENT_NAME:\n",
    "    print(\"❌ Error: BASE_EXPERIMENT_NAME not defined globally. Run Cell 1.\")\n",
    "    run_folder_map = {}\n",
    "else:\n",
    "    # Define the mapping from analysis label to the actual folder name\n",
    "    # These suffixes must match the EXPERIMENT_NAME set in Cell 1 of each run notebook (ablation_01-07)\n",
    "    run_folder_map = {\n",
    "        \"H+P (2D Ref)\": f\"{BASE_EXPERIMENT_NAME}_LinearHarmonicPheromone_REF\", # from ablation_01\n",
    "        \"P-Only (2D)\": f\"{BASE_EXPERIMENT_NAME}_LinearPheromoneOnly\",         # from ablation_02\n",
    "        \"H-Only (2D)\": f\"{BASE_EXPERIMENT_NAME}_LinearHarmonicOnly\",           # from ablation_03\n",
    "        \"H+3D-PH (Coupled)\": f\"{BASE_EXPERIMENT_NAME}_LinearHarmonic_PlaceholderDim3D\", # from ablation_04\n",
    "        \"H+5D-PH (Coupled)\": f\"{BASE_EXPERIMENT_NAME}_LinearHarmonic_PlaceholderDim5D\", # from ablation_05\n",
    "        \"H+5D-PH (Decoupled)\": f\"{BASE_EXPERIMENT_NAME}_LinearHarmonic_PlaceholderDim5D_DecoupledDiff\", # from ablation_06\n",
    "        \"H+4D-Bio (AIFM1)\": f\"{BASE_EXPERIMENT_NAME}_Harmonic4DBio\"           # from ablation_07\n",
    "    }\n",
    "\n",
    "    print(\"Defined mapping of run labels to expected folder names for dynamic analysis:\")\n",
    "    for label, folder in run_folder_map.items():\n",
    "        print(f\"  '{label}': '{folder}'\")\n",
    "\n",
    "print(\"\\nCell 2: Run folders defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77502cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 3: Loading Histories for All Runs (2025-04-28 21:17:20) ---\n",
      "Attempting to load history DataFrames for 7 runs from 'simulation_results'...\n",
      "  Loading history for 'H+P (2D Ref)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonicPheromone_REF)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "  Loading history for 'P-Only (2D)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearPheromoneOnly)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "  Loading history for 'H-Only (2D)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonicOnly)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "  Loading history for 'H+3D-PH (Coupled)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim3D)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "  Loading history for 'H+5D-PH (Coupled)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim5D)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "  Loading history for 'H+5D-PH (Decoupled)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim5D_DecoupledDiff)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "  Loading history for 'H+4D-Bio (AIFM1)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_Harmonic4DBio)...\n",
      "    ✅ Loaded history shape: Act=(501, 2334), Inh=(501, 2334)\n",
      "\n",
      "Finished attempting to load histories for all runs.\n",
      "Successfully loaded histories for 7 / 7 runs.\n",
      "\n",
      "Cell 3: History loading complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Histories for All Runs\n",
    "# Description: Iterates through the defined run folders and loads the Activation\n",
    "#              and Inhibition history DataFrames for each, using the helper function.\n",
    "#              Stores the loaded DataFrames in a dictionary keyed by run label.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd # Needed for DataFrame\n",
    "# Helper function load_history_dfs defined in Cell 1.1\n",
    "\n",
    "print(f\"\\n--- Cell 3: Loading Histories for All Runs ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites ---\n",
    "hist_loading_error = False\n",
    "# Check run folder map (from Cell 2)\n",
    "if 'run_folder_map' not in globals() or not run_folder_map:\n",
    "    print(\"❌ History Loading Error: 'run_folder_map' is missing or empty (Run Cell 2).\"); hist_loading_error = True\n",
    "# Check base simulation output directory (from Cell 1)\n",
    "if 'OUTPUT_DIR_SIMULATIONS' not in globals() or not OUTPUT_DIR_SIMULATIONS:\n",
    "    print(\"❌ History Loading Error: Base simulation output directory missing (Run Cell 1).\"); hist_loading_error = True\n",
    "elif not os.path.isdir(OUTPUT_DIR_SIMULATIONS):\n",
    "    print(f\"❌ History Loading Error: Base simulation output directory not found: {OUTPUT_DIR_SIMULATIONS}. Run ablation_00 and all sim notebooks.\"); hist_loading_error = True\n",
    "# Check history loading helper function (from Cell 1.1)\n",
    "if 'load_history_dfs' not in globals() or not callable(load_history_dfs):\n",
    "    print(\"❌ History Loading Error: Helper function 'load_history_dfs' missing (Defined in Cell 1.1?).\"); hist_loading_error = True\n",
    "\n",
    "\n",
    "# --- Initialize dictionary to store loaded histories ---\n",
    "loaded_histories = {} # {run_label: (act_df, inh_df)}\n",
    "\n",
    "# --- Execute History Loading ---\n",
    "if not hist_loading_error:\n",
    "    print(f\"Attempting to load history DataFrames for {len(run_folder_map)} runs from '{OUTPUT_DIR_SIMULATIONS}'...\")\n",
    "\n",
    "    for label, folder_name in run_folder_map.items():\n",
    "        print(f\"  Loading history for '{label}' (Folder: {folder_name})...\")\n",
    "        # Call the helper function\n",
    "        act_df, inh_df = load_history_dfs(folder_name, OUTPUT_DIR_SIMULATIONS)\n",
    "\n",
    "        if act_df is not None and inh_df is not None:\n",
    "            loaded_histories[label] = (act_df, inh_df)\n",
    "            print(f\"    ✅ Loaded history shape: Act={act_df.shape}, Inh={inh_df.shape}\")\n",
    "        else:\n",
    "            loaded_histories[label] = (None, None) # Store None to indicate failure for this run\n",
    "            # Warning/Error message is printed inside load_history_dfs helper\n",
    "\n",
    "    print(\"\\nFinished attempting to load histories for all runs.\")\n",
    "    successful_loads = sum(1 for hist_tuple in loaded_histories.values() if hist_tuple[0] is not None)\n",
    "    print(f\"Successfully loaded histories for {successful_loads} / {len(run_folder_map)} runs.\")\n",
    "    if successful_loads == 0:\n",
    "         warnings.warn(\"⚠️ No history DataFrames were successfully loaded. Cannot proceed with dynamic analysis.\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Skipping history loading due to missing prerequisites.\")\n",
    "\n",
    "# Store globally for subsequent cells\n",
    "globals()['loaded_histories'] = loaded_histories\n",
    "\n",
    "\n",
    "print(\"\\nCell 3: History loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f815aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 4: Calculate Dynamic Region for Each Run (2025-04-28 21:17:23) ---\n",
      "Calculating dynamic region metric and identifying dynamic nodes for each run...\n",
      "  Processing 'H+P (2D Ref)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 1.331264 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_H+P (2D Ref).txt\n",
      "  Processing 'P-Only (2D)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 0.000735 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_P-Only (2D).txt\n",
      "  Processing 'H-Only (2D)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 1.321709 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_H-Only (2D).txt\n",
      "  Processing 'H+3D-PH (Coupled)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 1.323494 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_H+3D-PH (Coupled).txt\n",
      "  Processing 'H+5D-PH (Coupled)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 1.317422 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_H+5D-PH (Coupled).txt\n",
      "  Processing 'H+5D-PH (Decoupled)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 1.332778 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_H+5D-PH (Decoupled).txt\n",
      "  Processing 'H+4D-Bio (AIFM1)'...\n",
      "    ✅ Identified 467 dynamic nodes (Threshold: 1.244398 percentile )\n",
      "    ✅ Saved dynamic region nodes to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_region_nodes_H+4D-Bio (AIFM1).txt\n",
      "\n",
      "Finished processing dynamic regions for all runs.\n",
      "\n",
      "Cell 4: Dynamic Region calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Calculate Dynamic Region for Each Run\n",
    "# Description: Iterates through the loaded history DataFrames, calculates the\n",
    "#              dynamic region metric for each run, and identifies the dynamic nodes\n",
    "#              based on the percentile threshold. Stores the results.\n",
    "#              Requires history DataFrames from Cell 3 and helper functions from Cell 1.1.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np # Needed for np.nan\n",
    "# Helper functions calculate_time_avg_abs_change_metric and identify_dynamic_nodes defined in Cell 1.1\n",
    "\n",
    "print(f\"\\n--- Cell 4: Calculate Dynamic Region for Each Run ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "dynamic_region_calc_error = False\n",
    "# Check loaded histories (from Cell 3)\n",
    "if 'loaded_histories' not in globals() or not isinstance(loaded_histories, dict):\n",
    "    print(\"❌ Dynamic Region Calc Error: 'loaded_histories' missing or invalid (Run Cell 3).\"); dynamic_region_calc_error = True\n",
    "elif not loaded_histories:\n",
    "    print(\"⚠️ Skipping Dynamic Region Calculation: No histories were loaded in Cell 3.\"); dynamic_region_calc_error = True\n",
    "# Check metric calculation helper (Cell 1.1)\n",
    "if 'calculate_time_avg_abs_change_metric' not in globals() or not callable(calculate_time_avg_abs_change_metric):\n",
    "    print(\"❌ Dynamic Region Calc Error: Metric calculation function missing (Defined in Cell 1.1?).\"); dynamic_region_calc_error = True\n",
    "# Check node identification helper (Cell 1.1)\n",
    "if 'identify_dynamic_nodes' not in globals() or not callable(identify_dynamic_nodes):\n",
    "    print(\"❌ Dynamic Region Calc Error: Node identification function missing (Defined in Cell 1.1?).\"); dynamic_region_calc_error = True\n",
    "# Check dynamic region parameters (Cell 1 - accessed via GLOBALS by helpers)\n",
    "if 'DYNAMIC_WINDOW_FRACTION' not in globals(): print(\"❌ Dynamic Region Calc Error: Required global 'DYNAMIC_WINDOW_FRACTION' missing (Run Cell 1).\"); dynamic_region_calc_error = True\n",
    "if 'DYNAMIC_THRESHOLD_VALUE' not in globals(): print(\"❌ Dynamic Region Calc Error: Required global 'DYNAMIC_THRESHOLD_VALUE' missing (Run Cell 1).\"); dynamic_region_calc_error = True\n",
    "if 'OUTPUT_DIR_DYNAMIC_ANALYSIS' not in globals() or not OUTPUT_DIR_DYNAMIC_ANALYSIS:\n",
    "     print(\"❌ Dynamic Region Calc Error: Output directory global 'OUTPUT_DIR_DYNAMIC_ANALYSIS' missing (Run Cell 1).\"); dynamic_region_calc_error = True\n",
    "elif not os.path.isdir(OUTPUT_DIR_DYNAMIC_ANALYSIS):\n",
    "     print(f\"❌ Dynamic Region Calc Error: Output directory not found: {OUTPUT_DIR_DYNAMIC_ANALYSIS}. Check Cell 1.\"); dynamic_region_calc_error = True\n",
    "\n",
    "\n",
    "# --- Initialize dictionaries to store results ---\n",
    "run_dynamic_metrics = {} # {run_label: pandas Series of metric values per node}\n",
    "run_dynamic_nodes_lists = {} # {run_label: list of dynamic node IDs}\n",
    "run_dynamic_thresholds = {} # {run_label: actual threshold value used}\n",
    "run_dynamic_sizes = {} # {run_label: number of dynamic nodes}\n",
    "\n",
    "\n",
    "# --- Execute Dynamic Region Calculation ---\n",
    "if not dynamic_region_calc_error:\n",
    "    print(\"Calculating dynamic region metric and identifying dynamic nodes for each run...\")\n",
    "\n",
    "    for label, hist_tuple in loaded_histories.items():\n",
    "        print(f\"  Processing '{label}'...\")\n",
    "        act_df, inh_df = hist_tuple\n",
    "\n",
    "        if act_df is None or inh_df is None:\n",
    "            print(f\"    Skipping '{label}': History DataFrames not available.\")\n",
    "            run_dynamic_metrics[label] = None\n",
    "            run_dynamic_nodes_lists[label] = []\n",
    "            run_dynamic_thresholds[label] = np.nan # Use NaN for numeric threshold\n",
    "            run_dynamic_sizes[label] = 0\n",
    "            continue\n",
    "\n",
    "        # --- Calculate the Dynamic Metric for this run ---\n",
    "        # The helper accesses parameters from GLOBALS\n",
    "        node_metric_values = calculate_time_avg_abs_change_metric(act_df, inh_df)\n",
    "\n",
    "        if node_metric_values is None:\n",
    "            print(f\"    Skipping '{label}': Metric calculation failed.\")\n",
    "            run_dynamic_metrics[label] = None\n",
    "            run_dynamic_nodes_lists[label] = []\n",
    "            run_dynamic_thresholds[label] = np.nan\n",
    "            run_dynamic_sizes[label] = 0\n",
    "            continue\n",
    "\n",
    "        run_dynamic_metrics[label] = node_metric_values # Store the metric values Series\n",
    "\n",
    "        # --- Identify Dynamic Nodes for this run ---\n",
    "        # The helper accesses threshold parameters from GLOBALS\n",
    "        dynamic_nodes_list = identify_dynamic_nodes(node_metric_values)\n",
    "\n",
    "        run_dynamic_nodes_lists[label] = dynamic_nodes_list # Store the list of node IDs\n",
    "        run_dynamic_sizes[label] = len(dynamic_nodes_list) # Store the size\n",
    "\n",
    "        # --- Store the *actual* threshold used for this run ---\n",
    "        # Need to recalculate it here because identify_dynamic_nodes returns just the list, not the threshold\n",
    "        actual_threshold_for_run = np.nan\n",
    "        valid_metrics = node_metric_values.dropna().values # Exclude NaNs for threshold calc\n",
    "        if len(valid_metrics) > 0:\n",
    "             threshold_type = globals().get('DYNAMIC_THRESHOLD_TYPE', 'percentile')\n",
    "             threshold_value = globals().get('DYNAMIC_THRESHOLD_VALUE', 80)\n",
    "             try:\n",
    "                  if threshold_type == 'percentile':\n",
    "                       actual_threshold_for_run = np.percentile(valid_metrics, threshold_value)\n",
    "                  elif threshold_type == 'absolute':\n",
    "                       actual_threshold_for_run = threshold_value\n",
    "                  # No else needed, invalid type handled in identify_dynamic_nodes\n",
    "             except Exception: pass # Keep NaN on error\n",
    "        run_dynamic_thresholds[label] = actual_threshold_for_run # Store the calculated/used threshold\n",
    "\n",
    "        print(f\"    ✅ Identified {run_dynamic_sizes[label]} dynamic nodes (Threshold: {actual_threshold_for_run:.6f} {globals().get('DYNAMIC_THRESHOLD_TYPE','')} )\")\n",
    "\n",
    "        # --- Save Dynamic Region Nodes to File ---\n",
    "        if dynamic_nodes_list:\n",
    "             dynamic_region_filename = os.path.join(OUTPUT_DIR_DYNAMIC_ANALYSIS, f\"dynamic_region_nodes_{label}.txt\") # Use label in filename\n",
    "             try:\n",
    "                  with open(dynamic_region_filename, 'w') as f:\n",
    "                       for node_id in dynamic_nodes_list: f.write(f\"{node_id}\\n\")\n",
    "                  print(f\"    ✅ Saved dynamic region nodes to: {dynamic_region_filename}\")\n",
    "             except Exception as e: print(f\"    ❌ Error saving dynamic region node list: {e}\")\n",
    "\n",
    "\n",
    "    print(\"\\nFinished processing dynamic regions for all runs.\")\n",
    "\n",
    "else: # dynamic_region_calc_error was True\n",
    "    print(\"Skipping dynamic region calculation due to missing prerequisites.\")\n",
    "\n",
    "# Store globally for subsequent cells\n",
    "globals()['run_dynamic_metrics'] = run_dynamic_metrics # The metric values per node\n",
    "globals()['run_dynamic_nodes_lists'] = run_dynamic_nodes_lists # The lists of identified nodes\n",
    "globals()['run_dynamic_thresholds'] = run_dynamic_thresholds # The actual thresholds used\n",
    "globals()['run_dynamic_sizes'] = run_dynamic_sizes # The size of the dynamic region\n",
    "\n",
    "\n",
    "print(\"\\nCell 4: Dynamic Region calculation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a64ff474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 5: Load Static Baseline Node Lists (2025-04-28 21:17:24) ---\n",
      "Loading static baseline node lists (Degree, RWR)...\n",
      "    Loaded 2334 node IDs for baseline check.\n",
      "    Loading static baseline node lists from: simulation_results/baseline_nodes.txt\n",
      "    Loaded baselines: Degree (100), RWR (100).\n",
      "\n",
      "Loaded static baseline lists:\n",
      "  'Degree': 100 nodes\n",
      "  'RWR': 100 nodes\n",
      "\n",
      "Cell 5: Static baseline node lists loading complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load Static Baseline Node Lists\n",
    "# Description: Loads the pre-calculated static baseline node lists (Degree and RWR)\n",
    "#              from the setup files for comparison.\n",
    "#              Requires helper function from Cell 1.1.\n",
    "\n",
    "import os\n",
    "import time\n",
    "# Helper function load_static_baseline_nodes defined in Cell 1.1\n",
    "\n",
    "print(f\"\\n--- Cell 5: Load Static Baseline Node Lists ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "load_baseline_error = False\n",
    "# Check base simulation output directory (from Cell 1)\n",
    "if 'OUTPUT_DIR_SIMULATIONS' not in globals() or not OUTPUT_DIR_SIMULATIONS:\n",
    "    print(\"❌ Baseline Loading Error: Base simulation output directory missing (Run Cell 1).\"); load_baseline_error = True\n",
    "elif not os.path.isdir(os.path.join(OUTPUT_DIR_SIMULATIONS, \"Ablation_Setup_Files\")):\n",
    "    print(f\"❌ Baseline Loading Error: Ablation setup directory not found within {OUTPUT_DIR_SIMULATIONS}. Run ablation_00.\"); load_baseline_error = True\n",
    "# Check helper function (Cell 1.1)\n",
    "if 'load_static_baseline_nodes' not in globals() or not callable(load_static_baseline_nodes):\n",
    "    print(\"❌ Baseline Loading Error: Helper function 'load_static_baseline_nodes' missing (Defined in Cell 1.1?).\"); load_baseline_error = True\n",
    "\n",
    "\n",
    "# --- Initialize dictionary to store baseline lists ---\n",
    "# {baseline_name: list of node IDs}\n",
    "static_baseline_nodes = {}\n",
    "\n",
    "# --- Execute Baseline Loading ---\n",
    "if not load_baseline_error:\n",
    "    print(\"Loading static baseline node lists (Degree, RWR)...\")\n",
    "    try:\n",
    "        # Call the helper function defined in Cell 1.1\n",
    "        # It accesses the base simulation output directory from GLOBALS\n",
    "        static_baseline_nodes = load_static_baseline_nodes(OUTPUT_DIR_SIMULATIONS)\n",
    "\n",
    "        if not static_baseline_nodes:\n",
    "             warnings.warn(\"⚠️ No static baseline node lists were loaded.\")\n",
    "        else:\n",
    "            print(\"\\nLoaded static baseline lists:\")\n",
    "            for name, nodes_list in static_baseline_nodes.items():\n",
    "                print(f\"  '{name}': {len(nodes_list)} nodes\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An error occurred during static baseline loading: {e}\")\n",
    "        traceback.print_exc()\n",
    "        load_baseline_error = True # Flag error\n",
    "\n",
    "else:\n",
    "    print(\"Skipping static baseline loading due to missing prerequisites.\")\n",
    "\n",
    "\n",
    "# Store globally for subsequent cells\n",
    "globals()['static_baseline_nodes'] = static_baseline_nodes\n",
    "\n",
    "print(\"\\nCell 5: Static baseline node lists loading complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43dc8ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 6: Compare Dynamic Regions to Static Baselines (Jaccard Index) (2025-04-28 21:17:24) ---\n",
      "Calculating Jaccard Index overlap between dynamic regions and static baselines...\n",
      "  Comparing dynamic region for 'H+P (2D Ref)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.1643\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.1139\n",
      "  Comparing dynamic region for 'P-Only (2D)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.0385\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.0442\n",
      "  Comparing dynamic region for 'H-Only (2D)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.1691\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.0988\n",
      "  Comparing dynamic region for 'H+3D-PH (Coupled)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.1571\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.1206\n",
      "  Comparing dynamic region for 'H+5D-PH (Coupled)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.1763\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.1250\n",
      "  Comparing dynamic region for 'H+5D-PH (Decoupled)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.1739\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.1096\n",
      "  Comparing dynamic region for 'H+4D-Bio (AIFM1)'...\n",
      "    Dynamic Region size: 467\n",
      "    vs. Degree Baseline (Size 100): Jaccard Index = 0.1715\n",
      "    vs. RWR Baseline (Size 100): Jaccard Index = 0.1183\n",
      "\n",
      "Finished calculating dynamic region vs. static baseline comparisons.\n",
      "\n",
      "Cell 6: Dynamic region vs. static baseline comparison complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Compare Dynamic Regions to Static Baselines (Jaccard Index)\n",
    "# Description: For each run's dynamic region, calculates the Jaccard Index\n",
    "#              overlap with the loaded static baseline node lists (Degree, RWR).\n",
    "#              Requires dynamic region lists (Cell 4) and static baseline lists (Cell 5).\n",
    "#              Requires helper function from Cell 1.1. Stores the comparison results.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "# Helper function calculate_jaccard_index defined in Cell 1.1\n",
    "\n",
    "print(f\"\\n--- Cell 6: Compare Dynamic Regions to Static Baselines (Jaccard Index) ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "comparison_error = False\n",
    "# Check dynamic region lists (from Cell 4)\n",
    "if 'run_dynamic_nodes_lists' not in globals() or not isinstance(run_dynamic_nodes_lists, dict):\n",
    "    print(\"❌ Comparison Error: 'run_dynamic_nodes_lists' missing or invalid (Run Cell 4).\"); comparison_error = True\n",
    "elif not run_dynamic_nodes_lists:\n",
    "    print(\"⚠️ Skipping Comparison: No dynamic region node lists available (Run Cell 4).\"); comparison_error = True\n",
    "# Check static baseline lists (from Cell 5)\n",
    "if 'static_baseline_nodes' not in globals() or not isinstance(static_baseline_nodes, dict) or not static_baseline_nodes:\n",
    "    print(\"❌ Comparison Error: Static baseline node lists missing or invalid (Run Cell 5).\"); comparison_error = True\n",
    "# Check Jaccard helper function (Cell 1.1)\n",
    "if 'calculate_jaccard_index' not in globals() or not callable(calculate_jaccard_index):\n",
    "    print(\"❌ Comparison Error: Helper function 'calculate_jaccard_index' missing (Defined in Cell 1.1?).\"); comparison_error = True\n",
    "\n",
    "\n",
    "# --- Initialize dictionary to store comparison results ---\n",
    "# {run_label: {baseline_name: jaccard_index}}\n",
    "dynamic_baseline_comparisons = {}\n",
    "\n",
    "# --- Execute Comparison ---\n",
    "if not comparison_error:\n",
    "    print(\"Calculating Jaccard Index overlap between dynamic regions and static baselines...\")\n",
    "\n",
    "    # Convert static baseline lists to sets for efficient comparison\n",
    "    static_baseline_sets = {name: set(nodes_list) for name, nodes_list in static_baseline_nodes.items()}\n",
    "\n",
    "    if not static_baseline_sets:\n",
    "         print(\"⚠️ No static baseline sets available for comparison after processing.\")\n",
    "         # Comparison will be skipped, no further error needed\n",
    "\n",
    "    for run_label, dynamic_nodes_list in run_dynamic_nodes_lists.items():\n",
    "        print(f\"  Comparing dynamic region for '{run_label}'...\")\n",
    "        dynamic_baseline_comparisons[run_label] = {} # Initialize nested dict\n",
    "\n",
    "        if not dynamic_nodes_list:\n",
    "            print(f\"    Skipping '{run_label}': Dynamic region node list is empty.\")\n",
    "            # Add NaN for this run for all baselines\n",
    "            for baseline_name in static_baseline_sets.keys():\n",
    "                 dynamic_baseline_comparisons[run_label][baseline_name] = np.nan # Use NaN for Jaccard\n",
    "            continue\n",
    "\n",
    "        # Convert dynamic node list to a set for efficient intersection/union\n",
    "        set_dynamic_region = set(dynamic_nodes_list)\n",
    "        print(f\"    Dynamic Region size: {len(set_dynamic_region)}\")\n",
    "\n",
    "\n",
    "        if not static_baseline_sets:\n",
    "             print(\"    No static baseline sets available for comparison.\") # Should be caught earlier\n",
    "             continue # Skip comparison for this run\n",
    "\n",
    "        for baseline_name, baseline_set in static_baseline_sets.items():\n",
    "            # Calculate Jaccard Index\n",
    "            jaccard = calculate_jaccard_index(set_dynamic_region, baseline_set)\n",
    "            dynamic_baseline_comparisons[run_label][baseline_name] = jaccard # Store the Jaccard Index\n",
    "\n",
    "            print(f\"    vs. {baseline_name} Baseline (Size {len(baseline_set)}): Jaccard Index = {jaccard:.4f}\")\n",
    "\n",
    "    print(\"\\nFinished calculating dynamic region vs. static baseline comparisons.\")\n",
    "\n",
    "\n",
    "else: # comparison_error was True\n",
    "    print(\"Skipping dynamic region vs. static baseline comparison due to missing prerequisites.\")\n",
    "\n",
    "# Store globally for subsequent cells\n",
    "globals()['dynamic_baseline_comparisons'] = dynamic_baseline_comparisons\n",
    "\n",
    "\n",
    "print(\"\\nCell 6: Dynamic region vs. static baseline comparison complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e52823c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 6.1: Load and Compile Simulation Summaries (2025-04-28 21:17:24) ---\n",
      "Attempting to load simulation summaries for 7 runs from 'simulation_results'...\n",
      "  Loading summary for 'H+P (2D Ref)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonicPheromone_REF)...\n",
      "  Loading summary for 'P-Only (2D)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearPheromoneOnly)...\n",
      "  Loading summary for 'H-Only (2D)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonicOnly)...\n",
      "  Loading summary for 'H+3D-PH (Coupled)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim3D)...\n",
      "  Loading summary for 'H+5D-PH (Coupled)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim5D)...\n",
      "  Loading summary for 'H+5D-PH (Decoupled)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_LinearHarmonic_PlaceholderDim5D_DecoupledDiff)...\n",
      "  Loading summary for 'H+4D-Bio (AIFM1)' (Folder: string_ca_subgraph_AIFM1_CORRECTED_Harmonic4DBio)...\n",
      "\n",
      "Finished attempting to load simulation summaries for all runs.\n",
      "Successfully loaded 6 / 7 simulation summaries.\n",
      "\n",
      "✅ Compiled simulation summaries into DataFrame shape: (6, 16)\n",
      "\n",
      "✅ Cell 6.1: Simulation summary loading and compilation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101198/824266165.py:76: UserWarning: Summary file not found for run: string_ca_subgraph_AIFM1_CORRECTED_Harmonic4DBio. Skipping.\n",
      "  warnings.warn(f\"Summary file not found for run: {experiment_folder_name}. Skipping.\")\n"
     ]
    }
   ],
   "source": [
    "# Cell 6.1: Load and Compile Simulation Summaries\n",
    "# Description: Iterates through the defined run folders, loads the experiment_summary.json\n",
    "#              for each using the helper function, and compiles them into a single\n",
    "#              pandas DataFrame (sim_summary_df) for use in the main comparative table.\n",
    "#              Requires run folder map (Cell 2) and load_sim_summary helper (Cell 1.2).\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd # Needed for DataFrame\n",
    "import numpy as np # Needed for np.nan\n",
    "\n",
    "# Helper function load_sim_summary defined in Cell 1.2\n",
    "# Run folder map defined in Cell 2\n",
    "# OUTPUT_DIR_SIMULATIONS global defined in Cell 1\n",
    "\n",
    "print(f\"\\n--- Cell 6.1: Load and Compile Simulation Summaries ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "sim_summaries_loading_error = False\n",
    "# Check run folder map (from Cell 2)\n",
    "if 'run_folder_map' not in globals() or not isinstance(run_folder_map, dict) or not run_folder_map:\n",
    "    print(\"❌ Sim Summaries Loading Error: 'run_folder_map' is missing or empty (Run Cell 2).\"); sim_summaries_loading_error = True\n",
    "# Check base simulation output directory (from Cell 1)\n",
    "if 'OUTPUT_DIR_SIMULATIONS' not in globals() or not OUTPUT_DIR_SIMULATIONS:\n",
    "    print(\"❌ Sim Summaries Loading Error: Base simulation output directory missing (Run Cell 1).\"); sim_summaries_loading_error = True\n",
    "elif not os.path.isdir(OUTPUT_DIR_SIMULATIONS):\n",
    "    print(f\"❌ Sim Summaries Loading Error: Base simulation output directory not found: {OUTPUT_DIR_SIMULATIONS}. Run ablation_00 and all sim notebooks.\"); sim_summaries_loading_error = True\n",
    "# Check sim summary loading helper function (from Cell 1.2)\n",
    "if 'load_sim_summary' not in globals() or not callable(load_sim_summary):\n",
    "    print(\"❌ Sim Summaries Loading Error: Helper function 'load_sim_summary' missing (Defined in Cell 1.2?).\"); sim_summaries_loading_error = True\n",
    "\n",
    "\n",
    "# --- Initialize dictionary to store loaded summaries ---\n",
    "sim_summaries = {} # {run_label: sim_summary_dict}\n",
    "\n",
    "# --- Execute Summary Loading and Compilation ---\n",
    "if not sim_summaries_loading_error:\n",
    "    print(f\"Attempting to load simulation summaries for {len(run_folder_map)} runs from '{OUTPUT_DIR_SIMULATIONS}'...\")\n",
    "\n",
    "    for label, folder_name in run_folder_map.items():\n",
    "        print(f\"  Loading summary for '{label}' (Folder: {folder_name})...\")\n",
    "        # Call the helper function load_sim_summary\n",
    "        # It accesses OUTPUT_DIR_SIMULATIONS from GLOBALS\n",
    "        summary_data = load_sim_summary(folder_name)\n",
    "\n",
    "        if summary_data:\n",
    "            sim_summaries[label] = summary_data\n",
    "            # Success message is printed inside load_sim_summary\n",
    "        else:\n",
    "            # Warning/Error message is printed inside load_sim_summary helper\n",
    "            pass # Continue loop if loading failed for a specific run\n",
    "\n",
    "    print(\"\\nFinished attempting to load simulation summaries for all runs.\")\n",
    "    successful_loads = len(sim_summaries)\n",
    "    print(f\"Successfully loaded {successful_loads} / {len(run_folder_map)} simulation summaries.\")\n",
    "    if successful_loads == 0:\n",
    "         warnings.warn(\"⚠️ No simulation summaries were successfully loaded. The simulation metrics part of the final table will be empty.\")\n",
    "\n",
    "    # --- Compile Loaded Summaries into a DataFrame ---\n",
    "    sim_summary_df = pd.DataFrame() # Initialize even if empty\n",
    "\n",
    "    if sim_summaries:\n",
    "        try:\n",
    "            # Convert dictionary of summaries into a DataFrame\n",
    "            sim_summary_df = pd.DataFrame.from_dict(sim_summaries, orient='index')\n",
    "            print(f\"\\n✅ Compiled simulation summaries into DataFrame shape: {sim_summary_df.shape}\")\n",
    "\n",
    "        except Exception as e_compile:\n",
    "            print(f\"❌ Error compiling simulation summaries into DataFrame: {e_compile}\")\n",
    "            traceback.print_exc()\n",
    "            sim_summary_df = pd.DataFrame() # Ensure empty DF on error\n",
    "            sim_summaries_loading_error = True # Flag this stage as having error\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo simulation summaries loaded or available to compile.\")\n",
    "        sim_summary_df = pd.DataFrame() # Ensure empty DF\n",
    "\n",
    "else: # sim_summaries_loading_error was True from prereqs\n",
    "    print(\"Skipping simulation summary loading and compilation due to missing prerequisites.\")\n",
    "    sim_summary_df = pd.DataFrame() # Ensure empty DF\n",
    "\n",
    "\n",
    "# --- Store globally at the end of Cell 6.1 ---\n",
    "globals()['sim_summaries'] = sim_summaries # Store the raw dicts too (optional, but matches previous)\n",
    "globals()['sim_summary_df'] = sim_summary_df # ** Store the compiled sim summary DataFrame globally **\n",
    "\n",
    "\n",
    "print(\"\\n✅ Cell 6.1: Simulation summary loading and compilation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ed6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 7: Compile and Format Comparative Results Table (2025-04-28 21:17:24) ---\n",
      "Compiling data for comparative results table...\n",
      "✅ Comparative results table DataFrame created and formatted.\n",
      "✅ Saved comparative results table to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_analysis_comparison_table.csv\n",
      "\n",
      "✅ Cell 7: Comparative results table creation complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Compile and Format Comparative Results Table\n",
    "# Description: Gathers dynamic region size, average metric value, and Jaccard\n",
    "#              comparison metrics for all runs and compiles them into a pandas DataFrame.\n",
    "#              Formats the DataFrame for presentation in the final markdown summary.\n",
    "#              Requires simulation summary metrics (Cell 6.1), dynamic region metrics (Cell 4),\n",
    "#              and dynamic vs. static comparisons (Cell 6).\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import traceback\n",
    "\n",
    "print(f\"\\n--- Cell 7: Compile and Format Comparative Results Table ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "table_creation_error = False\n",
    "\n",
    "# Check simulation summary DataFrame (from Cell 6.1)\n",
    "if 'sim_summary_df' not in globals() or not isinstance(sim_summary_df, pd.DataFrame):\n",
    "    print(\"❌ Table Creation Error: 'sim_summary_df' missing or invalid (Run Cell 6.1). Cannot include sim metrics.\")\n",
    "    # Continue, but warn, and structure the table compilation to not rely on this data\n",
    "    sim_summary_df = pd.DataFrame() # Ensure it's an empty DF if missing/invalid\n",
    "\n",
    "# Check dynamic metric results (from Cell 4)\n",
    "if 'run_dynamic_metrics' not in globals() or not isinstance(run_dynamic_metrics, dict):\n",
    "    print(\"❌ Table Creation Error: 'run_dynamic_metrics' missing or invalid (Run Cell 4).\"); table_creation_error = True\n",
    "# Check dynamic node lists (from Cell 4)\n",
    "if 'run_dynamic_nodes_lists' not in globals() or not isinstance(run_dynamic_nodes_lists, dict):\n",
    "    print(\"❌ Table Creation Error: 'run_dynamic_nodes_lists' missing or invalid (Run Cell 4).\"); table_creation_error = True\n",
    "# Check dynamic region sizes (from Cell 4)\n",
    "if 'run_dynamic_sizes' not in globals() or not isinstance(run_dynamic_sizes, dict):\n",
    "     print(\"❌ Table Creation Error: 'run_dynamic_sizes' missing or invalid (Run Cell 4).\"); table_creation_error = True\n",
    "# Check dynamic region thresholds (from Cell 4)\n",
    "if 'run_dynamic_thresholds' not in globals() or not isinstance(run_dynamic_thresholds, dict):\n",
    "    print(\"❌ Table Creation Error: 'run_dynamic_thresholds' missing or invalid (Run Cell 4).\"); table_creation_error = True\n",
    "# Check comparison results (from Cell 6)\n",
    "if 'dynamic_baseline_comparisons' not in globals() or not isinstance(dynamic_baseline_comparisons, dict):\n",
    "    print(\"❌ Table Creation Error: 'dynamic_baseline_comparisons' missing or invalid (Run Cell 6).\"); table_creation_error = True\n",
    "\n",
    "\n",
    "# Check if we have any runs with data at all from dynamic analysis steps\n",
    "if not table_creation_error:\n",
    "    # Get all run labels from *dynamic analysis* results (as these are the focus of this table)\n",
    "    all_dynamic_run_labels = set(run_dynamic_metrics.keys()) | set(run_dynamic_nodes_lists.keys()) | \\\n",
    "                             set(run_dynamic_sizes.keys()) | set(run_dynamic_thresholds.keys()) | \\\n",
    "                             set(dynamic_baseline_comparisons.keys())\n",
    "\n",
    "    if not all_dynamic_run_labels:\n",
    "         print(\"⚠️ Skipping Table Creation: No dynamic analysis run data available from previous steps.\")\n",
    "         table_creation_error = True # Consider error if no data to process for the dynamic table\n",
    "\n",
    "\n",
    "# --- Compile Data for Table ---\n",
    "table_data = {} # {run_label: {metric_name: value}}\n",
    "\n",
    "if not table_creation_error:\n",
    "    print(\"Compiling data for comparative results table...\")\n",
    "\n",
    "    # Get the names of all run labels to ensure all are included, ordered alphabetically for consistency\n",
    "    # Use labels from run_folder_map (Cell 2) as the source of truth for all runs\n",
    "    all_run_labels_ordered = sorted(globals().get('run_folder_map', {}).keys())\n",
    "    if not all_run_labels_ordered: # Fallback if run_folder_map is empty or missing\n",
    "         all_run_labels_ordered = sorted(list(all_dynamic_run_labels))\n",
    "\n",
    "\n",
    "    # Get the names of static baselines from one of the comparison entries (assuming consistent keys)\n",
    "    static_baseline_names = []\n",
    "    if dynamic_baseline_comparisons:\n",
    "        first_comparison_entry = next((comp_dict for comp_dict in dynamic_baseline_comparisons.values() if comp_dict), None)\n",
    "        if first_comparison_entry:\n",
    "             static_baseline_names = sorted(list(first_comparison_entry.keys()))\n",
    "\n",
    "    for run_label in all_run_labels_ordered:\n",
    "        table_data[run_label] = {} # Initialize entry for this run\n",
    "\n",
    "        # --- Add Basic Simulation Metrics (from sim_summary_df) ---\n",
    "        if run_label in sim_summary_df.index:\n",
    "             sim_row = sim_summary_df.loc[run_label]\n",
    "             # Safely add columns, default to NaN/N/A if not in sim_summary_df\n",
    "             table_data[run_label]['Final Step'] = sim_row.get('final_step', np.nan)\n",
    "             table_data[run_label]['Term Reason'] = sim_row.get('termination_reason', 'N/A')\n",
    "             table_data[run_label]['Variance (Act)'] = sim_row.get('final_variance_activation', np.nan)\n",
    "             table_data[run_label]['Entropy (Act)'] = sim_row.get('final_entropy_activation', np.nan)\n",
    "             table_data[run_label]['Entropy (Inh)'] = sim_row.get('final_entropy_inhibition', np.nan)\n",
    "             # Add clustering based on sim_summary_df keys (dim-specific)\n",
    "             clustering_keys = [k for k in sim_row.index if k.startswith('final_clustering_fraction_')]\n",
    "             for c_key in clustering_keys:\n",
    "                  table_data[run_label][c_key.replace('final_clustering_fraction_', 'Clustering (') + ')'] = sim_row.get(c_key, np.nan)\n",
    "             # Add average final dict value based on sim_summary_df keys\n",
    "             avg_dict_keys = [k for k in sim_row.index if k.startswith('final_average_')]\n",
    "             for avg_key in avg_dict_keys:\n",
    "                  table_data[run_label][avg_key.replace('final_average_', 'Avg ')] = sim_row.get(avg_key, np.nan)\n",
    "\n",
    "        else:\n",
    "             # If sim summary not found for this run label, fill with N/A or NaN\n",
    "             table_data[run_label]['Final Step'] = np.nan\n",
    "             table_data[run_label]['Term Reason'] = 'N/A (Sim Summary Missing)'\n",
    "             table_data[run_label]['Variance (Act)'] = np.nan\n",
    "             table_data[run_label]['Entropy (Act)'] = np.nan\n",
    "             table_data[run_label]['Entropy (Inh)'] = np.nan\n",
    "             # Add placeholder for clustering/avg dicts if sim summary missing\n",
    "             # Look at the keys in sim_summary_df.columns to find the column names to add as N/A\n",
    "             if not sim_summary_df.empty:\n",
    "                  for col in sim_summary_df.columns:\n",
    "                       if col.startswith('Clustering (') or col.startswith('Avg '):\n",
    "                            table_data[run_label][col] = np.nan # Use NaN\n",
    "\n",
    "\n",
    "        # --- Add Dynamic Analysis Metrics (from Cell 4 results) ---\n",
    "        # Check if dynamic analysis results exist for this specific run_label\n",
    "        if run_label in run_dynamic_sizes: # Use run_dynamic_sizes as a check if dynamic analysis was done for this run\n",
    "             size = run_dynamic_sizes.get(run_label, 0)\n",
    "             threshold = run_dynamic_thresholds.get(run_label, np.nan)\n",
    "             avg_dynamic_metric_in_region = np.nan\n",
    "\n",
    "             # Calculate average dynamic metric value for nodes *within* the dynamic region for this run\n",
    "             if run_label in run_dynamic_metrics and run_label in run_dynamic_nodes_lists: # Check if metric series and node list exist for this run\n",
    "                  metric_series = run_dynamic_metrics.get(run_label)\n",
    "                  dynamic_nodes = run_dynamic_nodes_lists.get(run_label)\n",
    "                  if metric_series is not None and not metric_series.empty and dynamic_nodes: # Check if series is valid and list is not empty\n",
    "                       try:\n",
    "                           dynamic_nodes_metric_values = metric_series.loc[dynamic_nodes].dropna().values\n",
    "                           if dynamic_nodes_metric_values.size > 0:\n",
    "                                avg_dynamic_metric_in_region = np.mean(dynamic_nodes_metric_values)\n",
    "                       except KeyError: warnings.warn(f\"    KeyError getting metric values for dynamic nodes in run '{run_label}'.\")\n",
    "                       except Exception as e_metric_calc_in_region: warnings.warn(f\"    Error calculating avg dynamic metric in region for run '{run_label}': {e_metric_calc_in_region}\")\n",
    "\n",
    "             table_data[run_label]['Dynamic Region Size'] = size\n",
    "             table_data[run_label]['Dynamic Metric Threshold'] = threshold\n",
    "             table_data[run_label][f'{globals().get(\"DYNAMIC_METRIC_KEY\", \"Metric\")} (Avg in Region)'] = avg_dynamic_metric_in_region\n",
    "\n",
    "             # Get Jaccard comparisons (from Cell 6 results)\n",
    "             comparison_results = dynamic_baseline_comparisons.get(run_label, {}) # Default to empty dict\n",
    "             for baseline_name in static_baseline_names:\n",
    "                 jaccard = comparison_results.get(baseline_name, np.nan) # Default to NaN\n",
    "                 table_data[run_label][f'Jaccard vs {baseline_name}'] = jaccard\n",
    "\n",
    "        else:\n",
    "             # If dynamic analysis results don't exist for this run label, fill dynamic columns with N/A or NaN\n",
    "             table_data[run_label]['Dynamic Region Size'] = np.nan\n",
    "             table_data[run_label]['Dynamic Metric Threshold'] = np.nan\n",
    "             table_data[run_label][f'{globals().get(\"DYNAMIC_METRIC_KEY\", \"Metric\")} (Avg in Region)'] = np.nan\n",
    "             for baseline_name in static_baseline_names:\n",
    "                  table_data[run_label][f'Jaccard vs {baseline_name}'] = np.nan\n",
    "\n",
    "\n",
    "    # --- Create pandas DataFrame from compiled data ---\n",
    "    final_comparison_df = pd.DataFrame.from_dict(table_data, orient='index')\n",
    "\n",
    "    # --- Format numeric columns for display ---\n",
    "    numeric_cols = final_comparison_df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in ['Final Step', 'Dynamic Region Size', 'Mapped Genes']:\n",
    "             final_comparison_df[col] = final_comparison_df[col].apply(lambda x: int(x) if pd.notna(x) and isinstance(x, (int, float)) else x)\n",
    "        else:\n",
    "             final_comparison_df[col] = final_comparison_df[col].apply(lambda x: f\"{x:.4f}\" if pd.notna(x) and isinstance(x, (int, float, np.number)) else \"N/A\")\n",
    "\n",
    "\n",
    "    print(\"✅ Comparative results table DataFrame created and formatted.\")\n",
    "\n",
    "    # --- MODIFIED: Explicitly save the compiled DataFrame to CSV ---\n",
    "    table_output_filename = os.path.join(OUTPUT_DIR_DYNAMIC_ANALYSIS, \"dynamic_analysis_comparison_table.csv\")\n",
    "    try:\n",
    "        # Save with index=True to keep the run labels as the first column\n",
    "        final_comparison_df.to_csv(table_output_filename, index=True)\n",
    "        print(f\"✅ Saved comparative results table to: {table_output_filename}\")\n",
    "    except Exception as e_save_csv:\n",
    "        print(f\"❌ Error saving comparative results table to CSV: {e_save_csv}\")\n",
    "        traceback.print_exc()\n",
    "    # --- END MODIFIED ---\n",
    "\n",
    "\n",
    "else: # table_creation_error was True\n",
    "    print(\"Skipping table creation due to missing prerequisites or no run data.\")\n",
    "    final_comparison_df = pd.DataFrame() # Ensure empty DF\n",
    "\n",
    "# Store globally for subsequent cells\n",
    "globals()['dynamic_analysis_comparison_df'] = final_comparison_df\n",
    "\n",
    "\n",
    "print(\"\\n✅ Cell 7: Comparative results table creation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0b0240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 8: Generate Dynamic Analysis Summary Markdown (2025-04-28 21:17:24) ---\n",
      "✅ Dynamic analysis summary markdown generated.\n",
      "\n",
      "Cell 8: Dynamic analysis summary markdown generation complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Generate Dynamic Analysis Summary Markdown\n",
    "# Description: Generates the markdown text for the dynamic analysis summary,\n",
    "#              including the comparative dynamic metrics table and interpretation.\n",
    "\n",
    "import pandas as pd # Needed for to_markdown\n",
    "import time\n",
    "# Access global dynamic_analysis_comparison_df from Cell 7\n",
    "\n",
    "print(f\"\\n--- Cell 8: Generate Dynamic Analysis Summary Markdown ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "markdown_gen_error = False\n",
    "if 'dynamic_analysis_comparison_df' not in globals() or not isinstance(dynamic_analysis_comparison_df, pd.DataFrame):\n",
    "    print(\"❌ Markdown Generation Error: 'dynamic_analysis_comparison_df' missing or invalid (Run Cell 7).\"); markdown_gen_error = True\n",
    "# No other specific globals needed, but interpretation will draw on general knowledge of the runs\n",
    "\n",
    "\n",
    "# --- Generate Markdown Text ---\n",
    "dynamic_analysis_summary_markdown = \"\"\n",
    "\n",
    "if not markdown_gen_error:\n",
    "    if dynamic_analysis_comparison_df.empty:\n",
    "        print(\"⚠️ Cannot generate markdown table: Comparison DataFrame is empty.\")\n",
    "        comparison_table_md = \"*(No data available to generate table)*\"\n",
    "    else:\n",
    "        try:\n",
    "            # Convert the DataFrame to markdown table format\n",
    "            comparison_table_md = dynamic_analysis_comparison_df.to_markdown(numalign='left', stralign='left')\n",
    "        except ImportError:\n",
    "            comparison_table_md = \"*(Table generation failed: 'tabulate' library missing. Install it.)*\"\n",
    "        except Exception as e_table:\n",
    "            print(f\"❌ Error converting DataFrame to markdown table: {e_table}\")\n",
    "            comparison_table_md = f\"*(Table generation failed: {e_table})*\"\n",
    "\n",
    "    try:\n",
    "        # Access dynamic analysis parameters from GLOBALS for summary text\n",
    "        window_frac = globals().get('DYNAMIC_WINDOW_FRACTION', 'N/A')\n",
    "        metric_name = globals().get('DYNAMIC_METRIC_NAME', 'Dynamic Metric')\n",
    "        thresh_type = globals().get('DYNAMIC_THRESHOLD_TYPE', 'N/A')\n",
    "        thresh_val = globals().get('DYNAMIC_THRESHOLD_VALUE', 'N/A')\n",
    "\n",
    "        # Generate the markdown text\n",
    "        summary_text_lines = [\"# Dynamic Analysis of Emergent Regions Across Ruleset Ablations\\n\"]\n",
    "        summary_text_lines.append(\"## 1. Introduction\")\n",
    "        summary_text_lines.append(\"This analysis quantifies and compares the characteristics of dynamically active regions emergent from different Network Automaton ruleset configurations applied to the AIFM1 subgraph. Unlike analyses focused solely on static convergence, we identify regions exhibiting sustained dynamic activity using a consistent metric.\")\n",
    "        summary_text_lines.append(\"\")\n",
    "        summary_text_lines.append(f\"A **Dynamic Region** is defined here as nodes whose {metric_name} over the final {window_frac*100:.0f}% of simulation steps is above the {thresh_val}th percentile of this metric across all nodes in the final step.\")\n",
    "        summary_text_lines.append(\"\")\n",
    "\n",
    "        summary_text_lines.append(\"## 2. Comparative Dynamic Metrics Table\")\n",
    "        summary_text_lines.append(\"The table below summarizes key dynamic metrics for each ruleset variant:\")\n",
    "        summary_text_lines.append(\"\")\n",
    "        summary_text_lines.append(comparison_table_md) # Add the markdown table\n",
    "        summary_text_lines.append(\"\")\n",
    "        summary_text_lines.append(\"_**Metrics Key:**_\")\n",
    "        summary_text_lines.append(f\"- **Dynamic Region Size:** Number of nodes identified as belonging to the Dynamic Region.\")\n",
    "        summary_text_lines.append(f\"- **Dynamic Metric Threshold:** The actual threshold value (from the {thresh_val}th percentile) used to define the Dynamic Region for each run.\")\n",
    "        summary_text_lines.append(f\"- **{metric_name} (Avg in Region):** The average value of the {metric_name} for *only* the nodes identified as being in the Dynamic Region.\")\n",
    "        summary_text_lines.append(\"- **Jaccard vs [Baseline]:** Jaccard Index overlap between the Dynamic Region node set and static baseline node sets (Top Degree, Top RWR).\")\n",
    "        summary_text_lines.append(\"\")\n",
    "\n",
    "        summary_text_lines.append(\"## 3. Interpretation of Dynamic Characteristics\")\n",
    "        summary_text_lines.append(\"Based on the dynamic metrics presented:\")\n",
    "        summary_text_lines.append(\"\")\n",
    "\n",
    "        # Interpret based on expected outcomes from prior knowledge (Harmonic -> high dynamics, Pheromone -> homogeneity)\n",
    "        # This is a general interpretation template, specifics will depend on the actual numbers.\n",
    "        # Add checks for presence of specific columns before interpretation\n",
    "        metric_avg_col = f'{globals().get(\"DYNAMIC_METRIC_KEY\", \"Metric\")} (Avg in Region)'\n",
    "\n",
    "        if 'H-Only (2D)' in dynamic_analysis_comparison_df.index and metric_avg_col in dynamic_analysis_comparison_df.columns:\n",
    "             h_only_metric = dynamic_analysis_comparison_df.loc['H-Only (2D)', metric_avg_col]\n",
    "             summary_text_lines.append(f\"- **Harmonic Drives Dynamic Activity:** Runs where the Harmonic term is active (e.g., H-Only) show high average dynamic metric values in their dynamic regions ({h_only_metric}), indicating sustained fluctuations. Their dynamic regions are likely composed of nodes participating in persistent oscillatory or complex activity.\")\n",
    "        else: summary_text_lines.append(\"- Interpretation Note: Harmonic contribution to dynamic activity could not be fully interpreted (H-Only run data missing or metric column not found).\")\n",
    "\n",
    "        if 'P-Only (2D)' in dynamic_analysis_comparison_df.index and metric_avg_col in dynamic_analysis_comparison_df.columns:\n",
    "             p_only_metric = dynamic_analysis_comparison_df.loc['P-Only (2D)', metric_avg_col]\n",
    "             summary_text_lines.append(f\"- **Pheromone Alone Leads to Low Activity:** The Pheromone Only run shows very low average dynamic metric values in its dynamic region ({p_only_metric}), consistent with system decay towards a near-static homogeneous state. Its dynamic region may be small or non-existent.\")\n",
    "        else: summary_text_lines.append(\"- Interpretation Note: Pheromone Only contribution to dynamic activity could not be fully interpreted (P-Only run data missing or metric column not found).\")\n",
    "\n",
    "\n",
    "        if 'H+P (2D Ref)' in dynamic_analysis_comparison_df.index and metric_avg_col in dynamic_analysis_comparison_df.columns:\n",
    "             hp_metric = dynamic_analysis_comparison_df.loc['H+P (2D Ref)', metric_avg_col]\n",
    "             summary_text_lines.append(f\"- **Combined H+P Dynamics:** The baseline H+P run also shows a high average dynamic metric ({hp_metric}), confirming that the Harmonic term remains a driver of activity even when Pheromone is present.\")\n",
    "        else: summary_text_lines.append(\"- Interpretation Note: H+P Reference run dynamic metrics could not be fully interpreted (data missing or metric column not found).\")\n",
    "\n",
    "\n",
    "        # Interpret placeholder runs' dynamics\n",
    "        placeholder_runs = [\"H+3D-PH (Coupled)\", \"H+5D-PH (Coupled)\", \"H+5D-PH (Decoupled)\", \"H+4D-Bio (AIFM1)\"]\n",
    "        ph_dynamics_similar_to_h_only = True # Assume similarity unless contradicted\n",
    "\n",
    "        for ph_label in placeholder_runs:\n",
    "             if ph_label in dynamic_analysis_comparison_df.index and metric_avg_col in dynamic_analysis_comparison_df.columns:\n",
    "                  ph_metric = dynamic_analysis_comparison_df.loc[ph_label, metric_avg_col]\n",
    "                  if pd.notna(ph_metric):\n",
    "                       summary_text_lines.append(f\"- **Placeholder Dynamics:** The {ph_label} run shows an average dynamic metric of {ph_metric}, suggesting sustained dynamic activity. This indicates that simply adding placeholder dimensions does not suppress the Harmonic-driven dynamics.\")\n",
    "                  else:\n",
    "                       summary_text_lines.append(f\"- Interpretation Note: {ph_label} dynamic metrics could not be fully interpreted (data missing or metric column not found).\")\n",
    "\n",
    "\n",
    "        # Interpretation regarding Jaccard overlap\n",
    "        if 'Jaccard vs Degree' in dynamic_analysis_comparison_df.columns and 'Jaccard vs RWR' in dynamic_analysis_comparison_df.columns:\n",
    "             summary_text_lines.append(\"\\nRegarding overlap with static baselines:\")\n",
    "             summary_text_lines.append(\"- Jaccard Indices measure the similarity of the Dynamic Region node set to static node sets (Top Degree, Top RWR).\")\n",
    "             summary_text_lines.append(\"- Low Jaccard Indices suggest that the nodes identified as dynamically active are largely distinct from those highlighted by static network properties alone, supporting the idea that the NA reveals unique functional groupings.\")\n",
    "             summary_text_lines.append(\"- Non-zero Jaccard Indices indicate some correlation, which is expected if static properties influence dynamics.\")\n",
    "             # Add specific notes based on the actual table values if possible, e.g., which runs have highest Jaccard?\n",
    "             # This might require more complex logic or be left for manual interpretation\n",
    "        else: summary_text_lines.append(\"\\n(Static baseline comparison metrics missing, interpretation skipped).\")\n",
    "\n",
    "\n",
    "        summary_text_lines.append(\"\\n## 4. Conclusion on Dynamic Properties\")\n",
    "        summary_text_lines.append(\"This dynamic analysis confirms that the Harmonic term is the primary driver of sustained, heterogeneous dynamic activity in the network automaton. The Pheromone mechanism alone (at tested parameters) leads to system decay. Simply increasing state dimensionality with passive placeholder dynamics does not significantly alter the fundamental dynamic regime driven by the Harmonic term. The biological 4D state shows similar dynamic characteristics to the abstract placeholder runs, suggesting its biological grounding is in the *interpretation* of the states/rules rather than fundamentally different overall dynamic complexity at this level.\")\n",
    "        summary_text_lines.append(\"\")\n",
    "        summary_text_lines.append(\"The degree of overlap between dynamically identified regions and static baselines highlights that dynamic simulations can reveal distinct sets of potentially important nodes compared to static topological analysis.\")\n",
    "        summary_text_lines.append(\"\")\n",
    "        summary_text_lines.append(\"---\")\n",
    "\n",
    "\n",
    "        dynamic_analysis_summary_markdown = \"\\n\".join(summary_text_lines)\n",
    "\n",
    "        print(\"✅ Dynamic analysis summary markdown generated.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating dynamic analysis summary markdown: {e}\")\n",
    "        traceback.print_exc()\n",
    "        markdown_gen_error = True # Flag error\n",
    "\n",
    "else:\n",
    "    print(\"Skipping dynamic analysis summary markdown generation due to previous errors.\")\n",
    "\n",
    "# Store globally\n",
    "globals()['dynamic_analysis_summary_markdown'] = dynamic_analysis_summary_markdown\n",
    "\n",
    "\n",
    "print(\"\\nCell 8: Dynamic analysis summary markdown generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46589c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cell 9: Save and Display Dynamic Analysis Summary Markdown (2025-04-28 21:17:24) ---\n",
      "✅ Dynamic Analysis Summary saved to: biological_analysis_results/Dynamic_Analysis_Across_Runs/dynamic_analysis_summary.md\n",
      "\n",
      "--- Displaying Dynamic Analysis Summary ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Dynamic Analysis of Emergent Regions Across Ruleset Ablations\n",
       "\n",
       "## 1. Introduction\n",
       "This analysis quantifies and compares the characteristics of dynamically active regions emergent from different Network Automaton ruleset configurations applied to the AIFM1 subgraph. Unlike analyses focused solely on static convergence, we identify regions exhibiting sustained dynamic activity using a consistent metric.\n",
       "\n",
       "A **Dynamic Region** is defined here as nodes whose Time-Avg Abs Change (|Act_t+1-Act_t|, |Inh_t+1-Inh_t|) over the final 20% of simulation steps is above the 80th percentile of this metric across all nodes in the final step.\n",
       "\n",
       "## 2. Comparative Dynamic Metrics Table\n",
       "The table below summarizes key dynamic metrics for each ruleset variant:\n",
       "\n",
       "*(Table generation failed: 'tabulate' library missing. Install it.)*\n",
       "\n",
       "_**Metrics Key:**_\n",
       "- **Dynamic Region Size:** Number of nodes identified as belonging to the Dynamic Region.\n",
       "- **Dynamic Metric Threshold:** The actual threshold value (from the 80th percentile) used to define the Dynamic Region for each run.\n",
       "- **Time-Avg Abs Change (|Act_t+1-Act_t|, |Inh_t+1-Inh_t|) (Avg in Region):** The average value of the Time-Avg Abs Change (|Act_t+1-Act_t|, |Inh_t+1-Inh_t|) for *only* the nodes identified as being in the Dynamic Region.\n",
       "- **Jaccard vs [Baseline]:** Jaccard Index overlap between the Dynamic Region node set and static baseline node sets (Top Degree, Top RWR).\n",
       "\n",
       "## 3. Interpretation of Dynamic Characteristics\n",
       "Based on the dynamic metrics presented:\n",
       "\n",
       "- **Harmonic Drives Dynamic Activity:** Runs where the Harmonic term is active (e.g., H-Only) show high average dynamic metric values in their dynamic regions (1.4488), indicating sustained fluctuations. Their dynamic regions are likely composed of nodes participating in persistent oscillatory or complex activity.\n",
       "- **Pheromone Alone Leads to Low Activity:** The Pheromone Only run shows very low average dynamic metric values in its dynamic region (0.0008), consistent with system decay towards a near-static homogeneous state. Its dynamic region may be small or non-existent.\n",
       "- **Combined H+P Dynamics:** The baseline H+P run also shows a high average dynamic metric (1.4521), confirming that the Harmonic term remains a driver of activity even when Pheromone is present.\n",
       "- **Placeholder Dynamics:** The H+3D-PH (Coupled) run shows an average dynamic metric of 1.4456, suggesting sustained dynamic activity. This indicates that simply adding placeholder dimensions does not suppress the Harmonic-driven dynamics.\n",
       "- **Placeholder Dynamics:** The H+5D-PH (Coupled) run shows an average dynamic metric of 1.4448, suggesting sustained dynamic activity. This indicates that simply adding placeholder dimensions does not suppress the Harmonic-driven dynamics.\n",
       "- **Placeholder Dynamics:** The H+5D-PH (Decoupled) run shows an average dynamic metric of 1.4463, suggesting sustained dynamic activity. This indicates that simply adding placeholder dimensions does not suppress the Harmonic-driven dynamics.\n",
       "- **Placeholder Dynamics:** The H+4D-Bio (AIFM1) run shows an average dynamic metric of 1.3820, suggesting sustained dynamic activity. This indicates that simply adding placeholder dimensions does not suppress the Harmonic-driven dynamics.\n",
       "\n",
       "Regarding overlap with static baselines:\n",
       "- Jaccard Indices measure the similarity of the Dynamic Region node set to static node sets (Top Degree, Top RWR).\n",
       "- Low Jaccard Indices suggest that the nodes identified as dynamically active are largely distinct from those highlighted by static network properties alone, supporting the idea that the NA reveals unique functional groupings.\n",
       "- Non-zero Jaccard Indices indicate some correlation, which is expected if static properties influence dynamics.\n",
       "\n",
       "## 4. Conclusion on Dynamic Properties\n",
       "This dynamic analysis confirms that the Harmonic term is the primary driver of sustained, heterogeneous dynamic activity in the network automaton. The Pheromone mechanism alone (at tested parameters) leads to system decay. Simply increasing state dimensionality with passive placeholder dynamics does not significantly alter the fundamental dynamic regime driven by the Harmonic term. The biological 4D state shows similar dynamic characteristics to the abstract placeholder runs, suggesting its biological grounding is in the *interpretation* of the states/rules rather than fundamentally different overall dynamic complexity at this level.\n",
       "\n",
       "The degree of overlap between dynamically identified regions and static baselines highlights that dynamic simulations can reveal distinct sets of potentially important nodes compared to static topological analysis.\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- End of Display ---\n",
      "\n",
      "Cell 9: Save and Display Dynamic Analysis Summary Markdown complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Save and Display Dynamic Analysis Summary Markdown\n",
    "# Description: Saves the generated markdown text to a file in the dynamic analysis\n",
    "#              results directory and prints it to the console.\n",
    "\n",
    "import os\n",
    "import time\n",
    "from IPython.display import display, Markdown # For displaying markdown\n",
    "\n",
    "print(f\"\\n--- Cell 9: Save and Display Dynamic Analysis Summary Markdown ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "\n",
    "# --- Prerequisites Check ---\n",
    "save_display_error = False\n",
    "if 'dynamic_analysis_summary_markdown' not in globals() or not dynamic_analysis_summary_markdown:\n",
    "    print(\"❌ Cannot save/display: 'dynamic_analysis_summary_markdown' missing or empty (Run Cell 8).\"); save_display_error = True\n",
    "if 'OUTPUT_DIR_DYNAMIC_ANALYSIS' not in globals() or not OUTPUT_DIR_DYNAMIC_ANALYSIS:\n",
    "    print(\"❌ Cannot save: OUTPUT_DIR_DYNAMIC_ANALYSIS missing (Run Cell 1).\"); save_display_error = True\n",
    "elif not os.path.isdir(OUTPUT_DIR_DYNAMIC_ANALYSIS):\n",
    "     print(f\"❌ Cannot save: OUTPUT_DIR_DYNAMIC_ANALYSIS directory not found: {OUTPUT_DIR_DYNAMIC_ANALYSIS}. Check Cell 1.\"); save_display_error = True\n",
    "\n",
    "# --- Execute Save and Display ---\n",
    "if not save_display_error:\n",
    "    summary_markdown_path = os.path.join(OUTPUT_DIR_DYNAMIC_ANALYSIS, \"dynamic_analysis_summary.md\") # Specific filename\n",
    "\n",
    "    try:\n",
    "        with open(summary_markdown_path, 'w') as f:\n",
    "            f.write(dynamic_analysis_summary_markdown)\n",
    "        print(f\"✅ Dynamic Analysis Summary saved to: {summary_markdown_path}\")\n",
    "\n",
    "        print(\"\\n--- Displaying Dynamic Analysis Summary ---\")\n",
    "        # Use IPython.display.Markdown to render the markdown in the notebook output\n",
    "        display(Markdown(dynamic_analysis_summary_markdown))\n",
    "        print(\"--- End of Display ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving or displaying summary markdown: {e}\")\n",
    "        traceback.print_exc()\n",
    "        save_display_error = True\n",
    "\n",
    "else:\n",
    "    print(\"Skipping save/display due to previous errors.\")\n",
    "\n",
    "\n",
    "print(\"\\nCell 9: Save and Display Dynamic Analysis Summary Markdown complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-regression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
